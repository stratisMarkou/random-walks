{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "num_source_bits = 2\n",
    "\n",
    "source_bits = np.random.choice([0, 1], num_source_bits, replace=True)\n",
    "\n",
    "print(source_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_T = np.array([[1, 0],\n",
    "                [0, 1],\n",
    "                [1, 0],\n",
    "                [1, 0],\n",
    "                [1, 1],\n",
    "                [1, 1],\n",
    "                [0, 1],\n",
    "                [0, 1]])\n",
    "\n",
    "H = np.array([[1, 0, 1, 0, 0, 0, 0, 0],\n",
    "              [1, 0, 0, 1, 0, 0, 0, 0],\n",
    "              [1, 1, 0, 0, 1, 0, 0, 0],\n",
    "              [1, 1, 0, 0, 0, 1, 0, 0],\n",
    "              [0, 1, 0, 0, 0, 0, 1, 0],\n",
    "              [0, 1, 0, 0, 0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(source):\n",
    "    return np.dot(G_T, source) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmitted = encode(source_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parities(received):\n",
    "    return np.dot(H, received) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parities(transmitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndromes = [(0, 1)] * 6\n",
    "syndromes = list(itertools.product(*syndromes))\n",
    "\n",
    "codes = [(0, 1)] * 8\n",
    "codes = list(itertools.product(*codes))\n",
    "\n",
    "decode_dict = {}\n",
    "\n",
    "\n",
    "for syndrome in syndromes:\n",
    "    \n",
    "    for code in codes:\n",
    "        \n",
    "        code_syndrome = np.dot(H, code) % 2\n",
    "        num_bits = np.sum(code)\n",
    "            \n",
    "        syndrome_tup = tuple(syndrome)\n",
    "        code_syndrome_tup = tuple(code_syndrome)\n",
    "        \n",
    "        if syndrome_tup == code_syndrome_tup:\n",
    "            \n",
    "            if syndrome_tup in decode_dict:\n",
    "                \n",
    "                if (num_bits < decode_dict[syndrome_tup][1]):\n",
    "                    decode_dict[syndrome_tup] = (code, num_bits)\n",
    "                \n",
    "            else:\n",
    "                decode_dict[syndrome_tup] = (code, num_bits)\n",
    "                \n",
    "# for k, v in decode_dict.items():\n",
    "#     print(k, v)\n",
    "                \n",
    "decode_dict = {k : v[0] for k, v in decode_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(received):\n",
    "    \n",
    "    syndrome = np.dot(H, received) % 2\n",
    "    \n",
    "    noise = decode_dict[tuple(syndrome)]\n",
    "    \n",
    "    decoded = (received + noise) % 2\n",
    "    \n",
    "    return decoded, syndrome, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01427\n"
     ]
    }
   ],
   "source": [
    "num_trans = int(1e5)\n",
    "flip_prob = 1e-1\n",
    "\n",
    "total_errors = 0\n",
    "total_bits = 2 * num_trans\n",
    "\n",
    "for n in range(num_trans):\n",
    "    \n",
    "    source_bits = np.random.choice([0, 1], num_source_bits, replace=True)\n",
    "    \n",
    "    encoded = encode(source_bits)\n",
    "    \n",
    "    noise = np.random.choice([0, 1], len(encoded), p=[1 - flip_prob, flip_prob], replace=True)\n",
    "    num_noisy = np.sum(noise)\n",
    "    \n",
    "    transmitted = (encoded + noise) % 2\n",
    "    \n",
    "    decoded, syndrome, decoded_noise = decode(transmitted)\n",
    "    \n",
    "    num_errors = np.sum(encoded[:2] != decoded[:2])\n",
    "    \n",
    "    if num_noisy <= 2 and num_errors != 0:\n",
    "        print(num_noisy, num_errors)\n",
    "    \n",
    "    total_errors = total_errors + num_errors\n",
    "    \n",
    "print(total_errors / total_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3331112591605596"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "\n",
    "n / (n + 2 + 2 * n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_T = np.array([[1, 0, 0, 0],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1],\n",
    "                [1, 0, 0, 0],\n",
    "                [1, 0, 0, 0],\n",
    "                [1, 1, 0, 0],\n",
    "                [1, 1, 0, 0],\n",
    "                [0, 1, 1, 0],\n",
    "                [0, 1, 1, 0],\n",
    "                [0, 0, 1, 1],\n",
    "                [0, 0, 1, 1],\n",
    "                [0, 0, 0, 1],\n",
    "                [0, 0, 0, 1]])\n",
    "\n",
    "H = np.array([[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "              [0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "              [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "              [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "              [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "              [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "              [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
    "\n",
    "def encode(source):\n",
    "    return np.dot(G_T, source) % 2\n",
    "\n",
    "\n",
    "def decode(received):\n",
    "    \n",
    "    syndrome = np.dot(H, received) % 2\n",
    "    \n",
    "    noise = decode_dict[tuple(syndrome)]\n",
    "    \n",
    "    decoded = (received + noise) % 2\n",
    "    \n",
    "    return decoded, syndrome, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [05:10<00:00,  3.30it/s]\n"
     ]
    }
   ],
   "source": [
    "syndromes = [(0, 1)] * 10\n",
    "syndromes = list(itertools.product(*syndromes))\n",
    "\n",
    "codes = [(0, 1)] * 14\n",
    "codes = list(itertools.product(*codes))\n",
    "\n",
    "decode_dict = {}\n",
    "\n",
    "for syndrome in tqdm(syndromes):\n",
    "    \n",
    "    for code in codes:\n",
    "        \n",
    "        code_syndrome = np.dot(H, code) % 2\n",
    "        num_bits = np.sum(code)\n",
    "            \n",
    "        syndrome_tup = tuple(syndrome)\n",
    "        code_syndrome_tup = tuple(code_syndrome)\n",
    "        \n",
    "        if syndrome_tup == code_syndrome_tup:\n",
    "            \n",
    "            if syndrome_tup in decode_dict:\n",
    "                \n",
    "                if (num_bits < decode_dict[syndrome_tup][1]):\n",
    "                    decode_dict[syndrome_tup] = (code, num_bits)\n",
    "                \n",
    "            else:\n",
    "                decode_dict[syndrome_tup] = (code, num_bits)\n",
    "                \n",
    "# for k, v in decode_dict.items():\n",
    "#     print(k, v)\n",
    "                \n",
    "decode_dict = {k : v[0] for k, v in decode_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 1 1 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 1 1 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
      "[1 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 1 1]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 0 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 1 0 0]\n",
      "[0 0 0 0 0 0 1 0 1 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 1 1 0 0]\n",
      "[0 1 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "[1 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 1 0]\n",
      "[1 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "[1 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 1 1]\n",
      "[0 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "[1 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[1 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 1 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 0 1]\n",
      "[0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
      "[1 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 1 1 0 0]\n",
      "[1 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 0 1 0]\n",
      "[0 1 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      "[0 0 0 0 1 0 1 1 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 0 1 0]\n",
      "[0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 1 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 0 0 1]\n",
      "[0 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "[0 1 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "[1 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 1 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      "[1 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 0 1 0 0]\n",
      "[1 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 1 1]\n",
      "[0 1 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 0 1 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 1 1 1 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 1 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      "[1 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "[1 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "[1 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 0 1 0 0]\n",
      "[0 1 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 0 1 0 0]\n",
      "[0 1 0 0 0 0 1 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "[0 0 1 0 0 0 0 0 1 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 0 1 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
      "[1 0 0 0 1 0 0 0 0 1 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "[1 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 0 1 0]\n",
      "[1 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 1 0 1 1 0 0 0 0 0 0]\n",
      "[1 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      "[0 1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 0 1 1 1 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 0 1 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 1 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[1 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "[1 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 1 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 1 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 0 0 1]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 1 1]\n",
      "[0 0 0 1 0 0 0 0 0 0 1 0 1 0]\n",
      "[0 0 1 0 0 0 0 0 0 1 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 1 0 0 0]\n",
      "[0 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "[0 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 0 1 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 0 1]\n",
      "[0 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "[0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 0 0 1]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 1 1]\n",
      "[1 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 0 1 0 0]\n",
      "[0 1 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "[1 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "[0 0 0 0 0 0 0 0 1 1 0 1 0 0]\n",
      "[0 1 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "[0 1 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 0 1 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 1 0 0 0]\n",
      "[0 0 0 0 0 1 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 1 0 1 0]\n",
      "[0 1 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 1 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 1 0 1 0]\n",
      "[0 1 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 1 1]\n",
      "[0 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 1 0 0 0 0 0 0 0 1 1 0 0]\n",
      "[0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "[1 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 1 1 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 1 0 0 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[1 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 1 1 0 0]\n",
      "[0 0 0 0 1 0 1 1 0 0 0 0 0 0]\n",
      "[1 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      "[1 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 1 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 1 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 1 0 1 0]\n",
      "[0 1 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[1 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 1 1 0 0]\n",
      "[1 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[1 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 1 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 1 1 0 0]\n",
      "[0 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 1 1 0 0]\n",
      "[1 0 0 0 1 0 0 0 0 1 0 0 0 0]\n",
      "[0 1 0 0 0 0 1 0 0 1 0 0 0 0]\n",
      "[1 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "[0 0 0 0 0 1 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 1 1]\n",
      "[0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      "[1 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "0.01735\n"
     ]
    }
   ],
   "source": [
    "num_source_bits = 4\n",
    "flip_prob = 1e-1\n",
    "\n",
    "num_trans = int(1e4)\n",
    "total_errors = 0\n",
    "total_bits = num_source_bits * num_trans\n",
    "\n",
    "for n in range(num_trans):\n",
    "    \n",
    "    source_bits = np.random.choice([0, 1], num_source_bits, replace=True)\n",
    "    \n",
    "    encoded = encode(source_bits)\n",
    "    \n",
    "    noise = np.random.choice([0, 1], len(encoded), p=[1 - flip_prob, flip_prob], replace=True)\n",
    "    num_noisy = np.sum(noise)\n",
    "    \n",
    "    transmitted = (encoded + noise) % 2\n",
    "    \n",
    "    decoded, syndrome, decoded_noise = decode(transmitted)\n",
    "    \n",
    "    num_errors = np.sum(encoded[:num_source_bits] != decoded[:num_source_bits])\n",
    "    \n",
    "    if num_noisy <= 2 and num_errors != 0:\n",
    "        print(num_noisy, num_errors)\n",
    "        \n",
    "    if num_noisy == 3 and num_errors > 0:\n",
    "        print(noise)\n",
    "    \n",
    "    total_errors = total_errors + num_errors\n",
    "    \n",
    "print(total_errors / total_bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decode_dict(H, syndrome_size, code_size):\n",
    "    \n",
    "    # All possible syndromes\n",
    "    syndromes = [(0, 1)] * syndrome_size\n",
    "    syndromes = list(itertools.product(*syndromes))\n",
    "\n",
    "    # All possible codes\n",
    "    codes = [(0, 1)] * code_size\n",
    "    codes = list(itertools.product(*codes))\n",
    "\n",
    "    # Decode dictionary to store {syndrome : code} pairs\n",
    "    decode_dict = {}\n",
    "\n",
    "    # For each syndrome, code with least 1s which produces the syndrome\n",
    "    for syndrome in tqdm(syndromes):\n",
    "        \n",
    "        syndrome_tup = tuple(syndrome)\n",
    "\n",
    "        # Loop over all codes, to find the code with least 1s\n",
    "        for code in codes:\n",
    "            \n",
    "            # Num bits in code\n",
    "            num_bits = np.sum(code)\n",
    "            \n",
    "            # Syndrome produced by the code\n",
    "            code_syndrome = np.dot(H, code) % 2\n",
    "            code_syndrome_tup = tuple(code_syndrome)\n",
    "\n",
    "            # If syndrome patterns match, replace code if better than previous\n",
    "            if syndrome_tup == code_syndrome_tup:\n",
    "\n",
    "                if syndrome_tup in decode_dict:\n",
    "\n",
    "                    if (num_bits < decode_dict[syndrome_tup][1]):\n",
    "                        decode_dict[syndrome_tup] = (code, num_bits)\n",
    "\n",
    "                else:\n",
    "                    decode_dict[syndrome_tup] = (code, num_bits)\n",
    "\n",
    "    # Take out the bit-numbers\n",
    "    decode_dict = {k : v[0] for k, v in decode_dict.items()}\n",
    "    \n",
    "    return decode_dict\n",
    "\n",
    "\n",
    "def encode(source, G_T):\n",
    "    return np.dot(G_T, source) % 2\n",
    "\n",
    "\n",
    "def decode(received, H, decode_dict):\n",
    "    \n",
    "    syndrome = np.dot(H, received) % 2\n",
    "    \n",
    "    noise = decode_dict[tuple(syndrome)]\n",
    "    \n",
    "    decoded = (received + noise) % 2\n",
    "    \n",
    "    return decoded, syndrome, noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The (8, 2) code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndrome_size = 6\n",
    "code_size = 8\n",
    "\n",
    "G_T = np.array([[1, 0],\n",
    "                [0, 1],\n",
    "                [1, 0],\n",
    "                [1, 0],\n",
    "                [1, 1],\n",
    "                [1, 1],\n",
    "                [0, 1],\n",
    "                [0, 1]])\n",
    "\n",
    "H = np.array([[1, 0, 1, 0, 0, 0, 0, 0],\n",
    "              [1, 0, 0, 1, 0, 0, 0, 0],\n",
    "              [1, 1, 0, 0, 1, 0, 0, 0],\n",
    "              [1, 1, 0, 0, 0, 1, 0, 0],\n",
    "              [0, 1, 0, 0, 0, 0, 1, 0],\n",
    "              [0, 1, 0, 0, 0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 208.51it/s]\n"
     ]
    }
   ],
   "source": [
    "decode_dict = build_decode_dict(H, syndrome_size=syndrome_size, code_size=code_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(bit error) 0.014135 rate 0.25\n"
     ]
    }
   ],
   "source": [
    "num_trans = int(1e5)\n",
    "flip_prob = 1e-1\n",
    "\n",
    "total_errors = 0\n",
    "total_bits = 2 * num_trans\n",
    "\n",
    "for n in range(num_trans):\n",
    "    \n",
    "    source_bits = np.random.choice([0, 1], num_source_bits, replace=True)\n",
    "    \n",
    "    encoded = encode(source_bits, G_T)\n",
    "    \n",
    "    noise = np.random.choice([0, 1], len(encoded), p=[1 - flip_prob, flip_prob], replace=True)\n",
    "    num_noisy = np.sum(noise)\n",
    "    \n",
    "    transmitted = (encoded + noise) % 2\n",
    "    \n",
    "    decoded, syndrome, decoded_noise = decode(transmitted, H, decode_dict)\n",
    "    \n",
    "    num_errors = np.sum(encoded[:2] != decoded[:2])\n",
    "    \n",
    "    if num_noisy <= 2 and num_errors != 0:\n",
    "        print(num_noisy, num_errors)\n",
    "    \n",
    "    total_errors = total_errors + num_errors\n",
    "    \n",
    "print(f'p(bit error) {total_errors / total_bits} rate {(code_size - syndrome_size)/code_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The (14, 4) code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndrome_size = 10\n",
    "code_size = 14\n",
    "\n",
    "G_T = np.array([[1, 0, 0, 0],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1],\n",
    "                [1, 0, 0, 0],\n",
    "                [1, 0, 0, 0],\n",
    "                [1, 1, 0, 0],\n",
    "                [1, 1, 0, 0],\n",
    "                [0, 1, 1, 0],\n",
    "                [0, 1, 1, 0],\n",
    "                [0, 0, 1, 1],\n",
    "                [0, 0, 1, 1],\n",
    "                [0, 0, 0, 1],\n",
    "                [0, 0, 0, 1]])\n",
    "\n",
    "H = np.array([[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "              [0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "              [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "              [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "              [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "              [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "              [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [05:14<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "decode_dict = build_decode_dict(H, syndrome_size=syndrome_size, code_size=code_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(bit error) 0.0197325 rate 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "num_source_bits = 4\n",
    "num_trans = int(1e5)\n",
    "flip_prob = 1e-1\n",
    "\n",
    "total_errors = 0\n",
    "total_bits = num_source_bits * num_trans\n",
    "\n",
    "for n in range(num_trans):\n",
    "    \n",
    "    source_bits = np.random.choice([0, 1], num_source_bits, replace=True)\n",
    "    \n",
    "    encoded = encode(source_bits, G_T)\n",
    "    \n",
    "    noise = np.random.choice([0, 1], len(encoded), p=[1 - flip_prob, flip_prob], replace=True)\n",
    "    num_noisy = np.sum(noise)\n",
    "    \n",
    "    transmitted = (encoded + noise) % 2\n",
    "    \n",
    "    decoded, syndrome, decoded_noise = decode(transmitted, H, decode_dict)\n",
    "    \n",
    "    num_errors = np.sum(encoded[:num_source_bits] != decoded[:num_source_bits])\n",
    "    \n",
    "    if num_noisy <= 2 and num_errors != 0:\n",
    "        print(num_noisy, num_errors)\n",
    "    \n",
    "    total_errors = total_errors + num_errors\n",
    "    \n",
    "print(f'p(bit error) {total_errors / total_bits} rate {(code_size - syndrome_size)/code_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The (14, 6) code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndrome_size = 8\n",
    "code_size = 14\n",
    "\n",
    "G_T = np.array([[1, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 1],\n",
    "                [1, 0, 0, 0, 0, 0],\n",
    "                [1, 1, 0, 0, 0, 0],\n",
    "                [1, 1, 1, 0, 0, 0],\n",
    "                [0, 1, 1, 1, 0, 0],\n",
    "                [0, 0, 1, 1, 1, 0],\n",
    "                [0, 0, 0, 1, 1, 1],\n",
    "                [0, 0, 0, 0, 1, 1],\n",
    "                [0, 0, 0, 0, 0, 1]])\n",
    "\n",
    "H = np.array([[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "              [1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "              [0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "              [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "              [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "              [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "              [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:17<00:00,  3.29it/s]\n"
     ]
    }
   ],
   "source": [
    "decode_dict = build_decode_dict(H, syndrome_size=syndrome_size, code_size=code_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(bit error) 0.053495 rate 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "num_source_bits = 6\n",
    "num_trans = int(1e5)\n",
    "flip_prob = 1e-1\n",
    "\n",
    "total_errors = 0\n",
    "total_bits = num_source_bits * num_trans\n",
    "\n",
    "for n in range(num_trans):\n",
    "    \n",
    "    source_bits = np.random.choice([0, 1], num_source_bits, replace=True)\n",
    "    \n",
    "    encoded = encode(source_bits, G_T)\n",
    "    \n",
    "    noise = np.random.choice([0, 1], len(encoded), p=[1 - flip_prob, flip_prob], replace=True)\n",
    "    num_noisy = np.sum(noise)\n",
    "    \n",
    "    transmitted = (encoded + noise) % 2\n",
    "    \n",
    "    decoded, syndrome, decoded_noise = decode(transmitted, H, decode_dict)\n",
    "    \n",
    "    num_errors = np.sum(encoded[:num_source_bits] != decoded[:num_source_bits])\n",
    "    \n",
    "    total_errors = total_errors + num_errors\n",
    "    \n",
    "print(f'p(bit error) {total_errors / total_bits} rate {(code_size - syndrome_size)/code_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The (12, 6) code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndrome_size = 6\n",
    "code_size = 12\n",
    "\n",
    "G_T = np.array([[1, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 0, 1, 0],\n",
    "                [0, 1, 1, 1, 0, 0],\n",
    "                [1, 0, 1, 1, 1, 0],\n",
    "                [0, 0, 0, 1, 1, 1],\n",
    "                [1, 0, 1, 0, 1, 1]])\n",
    "\n",
    "H = np.array([[1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "              [1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "              [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "              [1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "              [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0],\n",
    "              [1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:04<00:00, 13.51it/s]\n"
     ]
    }
   ],
   "source": [
    "decode_dict = build_decode_dict(H, syndrome_size=syndrome_size, code_size=code_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(bit error) 0.06634666666666666 rate 0.5\n"
     ]
    }
   ],
   "source": [
    "num_source_bits = 6\n",
    "num_trans = int(1e5)\n",
    "flip_prob = 1e-1\n",
    "\n",
    "total_errors = 0\n",
    "total_bits = num_source_bits * num_trans\n",
    "\n",
    "for n in range(num_trans):\n",
    "    \n",
    "    source_bits = np.random.choice([0, 1], num_source_bits, replace=True)\n",
    "    \n",
    "    encoded = encode(source_bits, G_T)\n",
    "    \n",
    "    noise = np.random.choice([0, 1], len(encoded), p=[1 - flip_prob, flip_prob], replace=True)\n",
    "    num_noisy = np.sum(noise)\n",
    "    \n",
    "    transmitted = (encoded + noise) % 2\n",
    "    \n",
    "    decoded, syndrome, decoded_noise = decode(transmitted, H, decode_dict)\n",
    "    \n",
    "    num_errors = np.sum(encoded[:num_source_bits] != decoded[:num_source_bits])\n",
    "    \n",
    "    total_errors = total_errors + num_errors\n",
    "    \n",
    "    if num_noisy <= 2 and num_errors != 0:\n",
    "        input(f'{noise} {syndrome} {np.dot(H, noise) % 2} {np.dot(H, decoded_noise) % 2} {num_errors} {num_noisy}')\n",
    "    \n",
    "print(f'p(bit error) {total_errors / total_bits} rate {(code_size - syndrome_size)/code_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(H, np.dot(G_T, source_bits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-random-walks",
   "language": "python",
   "name": "venv-random-walks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
