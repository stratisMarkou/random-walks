{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Probabilistic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.d-flex {\n",
       "    display: none!important;\n",
       "}\n",
       "\n",
       ".bd-toc nav {\n",
       "    opacity: 1;\n",
       "    max-height: 100vh!important;\n",
       "}\n",
       "\n",
       ".bd-toc .nav .nav {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".prev-next-bottom {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".footer {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".navbar_footer {\n",
       "\tdisplay: none;\n",
       "}\n",
       "\n",
       ".definition {\n",
       "\tbackground-color: rgba(123, 183, 223, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(123, 183, 223, 0.5);\n",
       "}\n",
       "\n",
       ".theorem {\n",
       "\tbackground-color: rgba(240, 213, 75, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(240, 213, 75, 0.5);\n",
       "}\n",
       "\n",
       ".lemma {\n",
       "\tbackground-color: rgba(255, 218, 185, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(255, 218, 185, 0.5);\n",
       "}\n",
       "\n",
       ".observation {\n",
       "\tbackground-color: rgba(178, 234, 188, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(178, 234, 188, 0.5);\n",
       "}\n",
       "\n",
       "details.proof {\n",
       "    border-width: 2px;\n",
       "\tborder-radius: 20px;\n",
       "\tborder-style: solid;\n",
       "\tbackground-color: rgba(128, 128, 128, 0.2);\n",
       "\tborder-color: rgba(128, 128, 128, 0.1);\n",
       "}\n",
       "\n",
       "\n",
       "details.proof div{\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "}\n",
       "\n",
       "details.proof {\n",
       "\tpadding: 0px 30px 0px 30px;\n",
       "}\n",
       "\n",
       "summary {\n",
       "\tmargin-left: -32px;\n",
       "\tpadding-left: 15px;\n",
       "\tpadding-right: 15px;\n",
       "}\n",
       "\n",
       "summary + * {\n",
       "    margin-top: 10px;\n",
       "}\n",
       "\n",
       ".tag_center-output div img {\n",
       "    display:block;\n",
       "    margin:auto;\n",
       "}\n",
       "\n",
       ".container {\n",
       "\twidth : 103% !important;\n",
       "}\n",
       "\n",
       "details > .math.notranslate.nohighlight {\n",
       "\tmargin-top: -50px;\n",
       "\tmargin-bottom: -15px;\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "\tfont-family: 'Amiri';\n",
       "\tfont-style: normal;\n",
       "\tfont-weight: 400;\n",
       "\tsrc: url(https://fonts.gstatic.com/s/amiri/v23/J7aRnpd8CGxBHpUutLMS7JNK.woff2) format('woff2');\n",
       "}\n",
       "\n",
       "\n",
       ".bd-sidebar {\n",
       "\tfont-family: Amiri;\n",
       "\tfont-size: 18px;\n",
       "}\n",
       "\n",
       ".bd-content {\n",
       "\tfont-family: Amiri;\n",
       "\tfont-size: 18px;\n",
       "}\n",
       "\n",
       ".MathJax_Display {\n",
       "\tmargin-top: 4px;\n",
       "\tmargin-bottom: 8px;\n",
       "}\n",
       "\n",
       ".cell.docutils.container {\n",
       "\tfont-size: 15px;\n",
       "}\n",
       "\n",
       "a.reference.internal.nav-link {\n",
       "    font-size: 0.8em;\n",
       "}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import *\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax\n",
    "\n",
    "from jax.random import PRNGKey\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import HTML, set_matplotlib_formats\n",
    "\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "css_style = open('../../../_static/custom_style.css', 'r').read()\n",
    "HTML(f'<style>{css_style}</style>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and learning\n",
    "\n",
    "<div class=\"lemma\">\n",
    "    \n",
    "**Result (DDPM evidence lower bound)** Given a distribution $p$ over $x_{0:T}$ and a distribution $q$ over $x_{1:T} | x_0$, with the following Markov forms\n",
    "    \n",
    "$$\\begin{align}\n",
    "p(x_{0:T}) = p(x_T) \\prod_{t = 1}^T p(x_{t-1} | x_t) ~~~\\text{ and }~~~ q(x_{1:T} | x_0) = \\prod_{t = 1}^T q(x_t | x_{t-1}),\n",
    "\\end{align}$$\n",
    "    \n",
    "the evidence lower bound (ELBO; also known as the Free Energy) to the marginal log likelihood $\\log p(x_0)$, is\n",
    "    \n",
    "$$\\begin{equation}\n",
    "\\mathbb{E}_q\\left[\\log \\frac{p(x_{0:T})}{q(x_{1:T} | x_0)}\\right] = \\mathbb{E}_q\\left[\\log p(x_T) + \\sum_{t=1}^T \\log \\frac{p(x_{t-1} | x_t)}{q(x_t | x_{t-1})} \\right].\n",
    "\\end{equation}$$\n",
    "    \n",
    "and can be rewritten as\n",
    "    \n",
    "$$\\begin{equation}\n",
    "\\mathbb{E}_q\\left[\\log \\frac{p(x_{0:T})}{q(x_{1:T} | x_0)}\\right] =  \\mathbb{E}_q\\left[\\text{KL}(q(x_T | x_0) || p(x_T)) + \\log p(x_0 | x_1) - \\sum^T_{t=2} \\text{KL}(q(x_{t-1} | x_t, x_0) || p(x_{t-1} | x_t)) \\right].\n",
    "\\end{equation}$$\n",
    "    \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<details class=\"proof\">\n",
    "<summary>Derivation: DDPM evidence lower bound</summary>\n",
    "<br>\n",
    "   \n",
    "By Jensen's inequality, for any $p$ and $q$, we have\n",
    "    \n",
    "$$\\begin{align}\n",
    "\\log p(x_0) \\geq \\mathbb{E}_q \\left[ \\log \\frac{p(x_{0:T})}{q(x_{1:T} | x_0)}\\right].\n",
    "\\end{align}$$\n",
    "    \n",
    "The left hand side above is the log-likelihood and the right hand side is the evidence lower bound (ELBO; also known as the Free Energy). Now, if $p$ and $q$ are have the forms\n",
    "    \n",
    "$$\\begin{align}\n",
    "p(x_{0:T}) &= p(x_T) \\prod_{t = 1}^T p(x_{t-1} | x_t), \\\\\n",
    "q(x_{1:T} | x_0) &= \\prod_{t = 1}^T q(x_t | x_{t-1}),\n",
    "\\end{align}$$\n",
    "    \n",
    "we can substitute these in the expression for the ELBO, and manipulate the term inside the expectation, to obtain\n",
    "    \n",
    "$$\\begin{align}\n",
    "\\log \\frac{p(x_{0:T})}{q(x_{1:T} | x_0)} &= \\log p(x_T) + \\sum_{t=1}^T \\log \\frac{p(x_{t-1} | x_t)}{q(x_t | x_{t-1}, x_0)} \\\\\n",
    "&= \\log p(x_T) + \\log \\frac{p(x_0 | x_1)}{q(x_1 | x_0)} + \\sum_{t=2}^T \\log \\frac{p(x_{t-1} | x_t)}{q(x_t | x_{t-1}, x_0)} \\\\\n",
    "&= \\log p(x_T) + \\log \\frac{p(x_0 | x_1)}{q(x_1 | x_0)} + \\sum_{t=2}^T \\left[\\log \\frac{p(x_{t-1} | x_t)}{q(x_t | x_{t-1}, x_0)} + \\log \\frac{q(x_{t-1} | x_0)}{q(x_t | x_0)} \\right] \\\\\n",
    "&= \\log \\frac{p(x_T)}{q(x_T | x_0)} + \\log p(x_0 | x_1) + \\sum_{t=2}^T \\left[\\log \\frac{p(x_{t-1} | x_t)}{q(x_t | x_{t-1}, x_0)} \\right],\n",
    "\\end{align}$$\n",
    "    \n",
    "where in the first line we have substituted the expressions for $p$ and $q$, in the second line we have pulled the first term of the sum outside the sum, in the third line we have used Bayes' rule, and in the fourth line we have used the fact that all the $\\log q(x_{t-1} | x_0)$ and $\\log q(x_t | x_0)$ terms cancel each other (a telescoping sum) except for the $\\log q(x_1 | x_0)$ and $\\log q(x_T | x_0)$ terms. Now, using the facts that\n",
    "   \n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_q\\left[ \\log \\frac{q(x_{t-1} | x_t, x_0)}{p(x_{t-1} | x_t)} \\right] &= \\mathbb{E}_q\\Bigg[ \\text{KL}(q(x_{t-1} | x_t, x_0) || p(x_{t-1} | x_t)) \\Bigg]\\\\\n",
    "\\mathbb{E}_q\\left[ \\log \\frac{p(x_T)}{q(x_T | x_0)} \\right] &= \\mathbb{E}_q\\Bigg[ \\text{KL}(q(x_T | x_0) || p(x_T)) \\Bigg]\n",
    "\\end{align}$$\n",
    "    \n",
    "we arrive at the result\n",
    "    \n",
    "$$\\begin{align}\n",
    "\\log p(x_0) \\geq \\mathbb{E}_q\\left[\\text{KL}(q(x_T | x_0) || p(x_T)) + \\log p(x_0 | x_1) - \\sum^T_{t=2} \\text{KL}(q(x_{t-1} | x_t, x_0) || p(x_{t-1} | x_t)) \\right].\n",
    "\\end{align}$$\n",
    "    \n",
    "</details>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<details class=\"proof\">\n",
    "<summary>Note: Why rewriting the ELBO is useful (Rao-Blackwellisation)</summary>\n",
    "<br>\n",
    "    \n",
    "The result above is useful for the following reason. In order to learn the generative model $p$, we will need to evaluate the ELBO and its gradients with respect to the parameters of $p$. Because the expectation over $q$ is intractable, we will have to use an approximation, such as Monte Carlo with the reparameterisation trick for computing gradients. The initial form of the ELBO\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\mathbb{E}_q\\left[\\log \\frac{p(x_{0:T})}{q(x_{1:T} | x_0)}\\right] = \\mathbb{E}_q\\left[\\log p(x_T) + \\sum_{t=1}^T \\log \\frac{p(x_{t-1} | x_t)}{q(x_t | x_{t-1}, x_0)} \\right],\n",
    "\\end{equation}$$\n",
    "\n",
    "is sufficient for this purpose. In particular, one could draw samples from $q(x_{1:T} | x_0)$ and use them to evaluate a Monte Carlo approximation of the expectation above. However, the usefulness of this estimator will depend on its accuracy, that is the amount of random error present due to the Monte Carlo approximation. Rewriting the expression into\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\mathbb{E}_q\\left[\\log \\frac{p(x_{0:T})}{q(x_{1:T} | x_0)}\\right] =  \\mathbb{E}_q\\left[\\text{KL}(q(x_T | x_0) || p(x_T)) + \\log p(x_0 | x_1) - \\sum^T_{t=2} \\text{KL}(q(x_{t-1} | x_t, x_0) || p(x_{t-1} | x_t)) \\right],\n",
    "\\end{equation}$$\n",
    "    \n",
    "allows us to reduce the random error, because we have already performed some of the expectations. For example, in the proof above, we have used the fact that\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\mathbb{E}_q\\left[ \\log \\frac{q(x_{t-1} | x_t, x_0)}{p(x_{t-1} | x_t)} \\right] = \\mathbb{E}_q\\Bigg[ \\text{KL}(q(x_{t-1} | x_t, x_0) || p(x_{t-1} | x_t)) \\Bigg],\n",
    "\\end{equation}$$\n",
    "    \n",
    "in which $x_{t-1}$ has already been integrated out. A simple Monte Carlo estimate of the right hand side will typically yield smaller (and certainly no greater) variance than a simple Monte Carlo estimate of the left hand side.\n",
    "\n",
    "</details>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"lemma\">\n",
    "    \n",
    "**Result (Closed-form expressions for $q$)** Given a sequence of noise variances $\\beta_t$, suppose\n",
    "    \n",
    "$$\\begin{equation}\n",
    "q(x_t | x_{t-1}) = \\mathcal{N}\\left(x_t; \\sqrt{1 - \\beta_t} x_t, \\beta_t I\\right),\n",
    "\\end{equation}$$\n",
    "    \n",
    "and define $\\alpha_t = (1 - \\beta_t)$ and $\\bar{\\alpha}_t = \\prod_{t' = 1}^t \\alpha_{t'}$. Then\n",
    "    \n",
    "$$\\begin{align}\n",
    "q(x_t | x_0) &= \\mathcal{N}\\left(x_t; \\sqrt{\\bar{\\alpha}_t} x_{t-1}, (1 - \\bar{\\alpha}_t) I\\right) \\\\\n",
    "q(x_{t-1} | x_t, x_0) &= \\mathcal{N}(x_{t-1}; \\tilde{\\mu}_t(x_t, x_0), \\tilde{\\beta}_t I),\n",
    "\\end{align}$$\n",
    " \n",
    "where $\\tilde{\\mu}_t(x_t, x_0)$ and $\\tilde{\\beta}_t$ are defined as\n",
    "    \n",
    "$$\\begin{equation}\n",
    "\\tilde{\\mu}_t(x_t, x_0) = \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1 - \\bar{\\alpha}_{t-1}} x_0 + \\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_{t-1}} x_t ~~\\text{ and }~~ \\tilde{\\beta}_t = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t}\n",
    "\\end{equation}$$\n",
    "    \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "\n",
    "<details class=\"proof\">\n",
    "<summary>Derivation: Closed-form expression for $q$</summary>\n",
    "<br>\n",
    "   \n",
    "First, note that since $q(x_{1:T} | x_0)$ is Gaussian, all conditionals and marginals of $q$ which we consider in this derivation are also Gaussian. We will show the expression for $q(x_t | x_0)$ by induction. For $t = 1$, we have\n",
    "    \n",
    "$$\\begin{align}\n",
    "q(x_1 | x_0) = \\mathcal{N}\\left(x_1; \\sqrt{1 - \\beta_1} x_0, \\beta_1 I\\right) = \\mathcal{N}\\left(x_t; \\sqrt{\\bar{\\alpha}_1} x_0, (1 - \\bar{\\alpha}_0) I\\right),\n",
    "\\end{align}$$\n",
    "    \n",
    "where the first equation holds by the definition of $q(x_t | x_{t-1})$, and the second line follows by the definitions of $\\alpha_t$ and $\\bar{\\alpha}_t$. Now, suppose the expression holds for $n = k$, that is\n",
    "    \n",
    "$$\\begin{equation}\n",
    "q(x_k | x_0) = \\mathcal{N}\\left(x_k; \\sqrt{\\bar{\\alpha}_k} x_{k-1}, (1 - \\bar{\\alpha}_k) I\\right).\n",
    "\\end{equation}$$\n",
    "    \n",
    "Then, for $t = k+1$ we have\n",
    "    \n",
    "$$\\begin{align}\n",
    "\\mathbb{E}\\left[x_{k+1} | x_0\\right] &= \\mathbb{E}\\left[\\sqrt{1 - \\beta_{k+1}} x_k + \\sqrt{\\beta_{k+1}} \\epsilon_{k+1} | x_0\\right] \\\\\n",
    "&= \\sqrt{1 - \\beta_{k+1}} \\mathbb{E}\\left[x_k | x_0\\right] \\\\\n",
    "&= \\sqrt{\\alpha_{k+1}} \\sqrt{\\bar{\\alpha}_k} \\\\\n",
    "&= \\sqrt{\\bar{\\alpha}_{k+1}},\n",
    "\\end{align}$$\n",
    "\n",
    "for the expectation, and\n",
    "    \n",
    "$$\\begin{align}\n",
    "\\mathbb{V}\\left[x_{k+1} | x_0\\right] &= \\mathbb{V}\\left[\\sqrt{1 - \\beta_{k+1}} x_k + \\sqrt{\\beta_{k+1}} \\epsilon_{k+1} | x_0\\right] \\\\\n",
    "&= (1 - \\beta_{k+1}) \\mathbb{V}\\left[x_k | x_0\\right] + \\beta_{k+1} \\\\\n",
    "&= \\alpha_{k+1} (1 - \\bar{\\alpha}_k) + (1-\\alpha_{k+1}) \\\\\n",
    "&= 1 - \\bar{\\alpha}_{k+1}\n",
    "\\end{align}$$\n",
    "    \n",
    "for the covariance, which shoes the inductive step. Since the base case and the inductive step holds, the expression for $q(x_t | x_0)$ follows by induction. For the second part of the result, by Bayes' rule, we have \n",
    "    \n",
    "$$\\begin{equation}\n",
    "q(x_{t-1} | x_t, x_0) = \\frac{q(x_t | x_{t-1}, x_0) q(x_{t-1} | x_0)}{q(x_t | x_0)}.\n",
    "\\end{equation}$$\n",
    "    \n",
    "Since $q(x_{t-1} | x_t, x_0)$ is a Gaussian in $x_{t-1}$, it suffices to compute its mean and covariance. To do this, we will drop all terms which are not dependent on $x_{t-1}$. In particular, we have\n",
    "    \n",
    "$$\\begin{equation}\n",
    "q(x_{t-1} | x_t, x_0) \\propto q(x_t | x_{t-1}, x_0) q(x_{t-1} | x_0) = q(x_t | x_{t-1}) q(x_{t-1} | x_0),\n",
    "\\end{equation}$$\n",
    "    \n",
    "To compute\n",
    "    \n",
    "    \n",
    "$$\\begin{equation}\n",
    "q(x_{t-1} | x_t, x_0) \\propto q(x_t | x_{t-1}, x_0) q(x_{t-1} | x_0) = q(x_t | x_{t-1}) q(x_{t-1} | x_0) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t} x_t, \\beta_t I) \\mathcal{N}(x_{t-1}; \\sqrt{\\bar{\\alpha}_{t-1}} x_{t-1}, (1 - \\bar{\\alpha}_{t-1}) I),\n",
    "\\end{equation}$$\n",
    "    \n",
    "and considering \n",
    "    \n",
    "</details>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "To implement the DDPM, we'll need a few parts. We need to implement the forward (noising) and the reverse (denoising) process, and the model's loss function.\n",
    "\n",
    "### Network architecture\n",
    "\n",
    "The denoising (generative) process is parameterised by a neural network. We have a lot of flexibility in specifying this network and the choice of architecture is probably largely dependent on the application of interest. In this example, we will opt to use a simple variant of a UNet architecture,{cite}`ronneberger2015u` because this is generally quick and easy to train. We'll choose roughly sensible hyperparameter settings, and won't spend time trying to optimise the architecture further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(eqx.Module):\n",
    "    \"\"\"Convenience class for the identity function.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return x\n",
    "\n",
    "    \n",
    "class UNetBlock(eqx.Module):\n",
    "    \"\"\"Bulk of the UNet architecture. This is constructed recursively, by\n",
    "    stacking a convolution and a transpose convolution before and after another\n",
    "    UNet block, respectively, whose number of UNet layers is one than the\n",
    "    current one, that is\n",
    "    \n",
    "        UNetBlock[depth] = ConvTranpose o UNetBlock[depth-1] o Conv\n",
    "        \n",
    "    where o is function composition.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sub-modules are a downwards (regular) convolution, the UNet sub-block\n",
    "    # and an upwards (transpose) convolution\n",
    "    down_conv: eqx.Module\n",
    "    sub_block: eqx.Module\n",
    "    up_conv: eqx.Module\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            layers: int,\n",
    "            num_channels: int,\n",
    "            kernel_size: int,\n",
    "            dim: int,\n",
    "            key: PRNGKey,\n",
    "        ):\n",
    "        \"\"\"Initialise the UNetBlock.\n",
    "        \n",
    "        Arguments:\n",
    "            layers       : int, number of layers (conv + transpose pairs)\n",
    "            num_channels : int, number of input channels\n",
    "            kernel_size  : int, kernel size (square shape)\n",
    "            dim          : int, dimension of the convolutions\n",
    "            key          : jax.random.PRNGKey, random key to use\n",
    "        \"\"\"\n",
    "        \n",
    "        assert layers >= 0\n",
    "        assert kernel_size % 2 == 1\n",
    "        \n",
    "        # Initialise regular (downwards) conv layer\n",
    "        key, init_key = jax.random.split(key)\n",
    "        self.down_conv = eqx.nn.Conv(\n",
    "            num_spatial_dims=dim,\n",
    "            in_channels=num_channels,\n",
    "            out_channels=2*num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=2,\n",
    "            padding=(kernel_size-1)//2,\n",
    "            key=init_key,\n",
    "        )\n",
    "            \n",
    "        # Initialise UNet sub-block\n",
    "        key, init_key = jax.random.split(key)\n",
    "        self.sub_block = UNetBlock(\n",
    "            layers=layers-1,\n",
    "            num_channels=2*num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            dim=dim,\n",
    "            key=init_key,\n",
    "        ) if layers > 0 else Identity()\n",
    "\n",
    "        # Initialise transpose (upwards) conv layer\n",
    "        key, init_key = jax.random.split(key)\n",
    "        self.up_conv = eqx.nn.ConvTranspose(\n",
    "            num_spatial_dims=dim,\n",
    "            in_channels=2*num_channels if layers == 0 else 4*num_channels,\n",
    "            out_channels=num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            output_padding=1,\n",
    "            stride=2,\n",
    "            padding=(kernel_size-1)//2,\n",
    "            key=init_key,\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "                \n",
    "        # Store x for skip connection\n",
    "        skip = x\n",
    "        \n",
    "        # Apply downwards convolution, sub-block and upwards convolution\n",
    "        x = jax.nn.relu(self.down_conv(x))\n",
    "        x = self.sub_block(x)\n",
    "        x = jax.nn.relu(self.up_conv(x))\n",
    "        \n",
    "        # Concatenate network output with its input for the skip connection\n",
    "        x = jnp.concatenate([x, skip], axis=0)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class UNet(eqx.Module):\n",
    "    \"\"\"Full UNet architecture. This consists of a UNetBlock, together with an\n",
    "    initial (regular) convolution and a final (transpose) convolution, to\n",
    "    bring the input and output numbers of channels to pre-specified numbers.\n",
    "    The full UNet architecture is\n",
    "    \n",
    "        UNet = ConvTranpose o UNetBlock o Conv\n",
    "        \n",
    "    where o is function composition.\n",
    "    \"\"\"\n",
    "    \n",
    "    unet_block: UNetBlock\n",
    "    in_conv: eqx.Module\n",
    "    out_conv: eqx.Module\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            unet_depth: int,\n",
    "            num_in_channels: int,\n",
    "            num_out_channels: int,\n",
    "            num_channels: int,\n",
    "            kernel_size: int,\n",
    "            dim: int,\n",
    "            key: PRNGKey,\n",
    "        ):\n",
    "        \"\"\"Initialise the UNet.\n",
    "        \n",
    "        Arguments:\n",
    "            unet_depth       : int, number of layers (conv + transpose pairs)\n",
    "            num_in_channels  : int, number of input channels\n",
    "            num_out_channels : int, number of output channels\n",
    "            num_channels     : int, number of UNetBlock input channels\n",
    "            kernel_size      : int, kernel size (square shape)\n",
    "            dim              : int, dimension of the convolutions\n",
    "            key              : jax.random.PRNGKey, random key to use\n",
    "        \"\"\"\n",
    "        \n",
    "        if not (unet_depth >= 1):\n",
    "            raise ValueError(f\"unet_depth must be >= 1, found {unet_depth}\")\n",
    "        \n",
    "        # Initialise first (regular) convolution\n",
    "        key, init_key = jax.random.split(key)\n",
    "        self.in_conv = eqx.nn.Conv(\n",
    "            num_spatial_dims=dim,\n",
    "            in_channels=num_in_channels,\n",
    "            out_channels=num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=(kernel_size-1)//2,\n",
    "            stride=1,\n",
    "            key=init_key,\n",
    "        )\n",
    "        \n",
    "        # Initialise UNetBlock\n",
    "        key, init_key = jax.random.split(key)\n",
    "        self.unet_block = UNetBlock(\n",
    "            layers=unet_depth-1,\n",
    "            num_channels=num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            dim=dim,\n",
    "            key=init_key,\n",
    "        )\n",
    "        \n",
    "        # Initialise last (transpose) convolution\n",
    "        key, init_key = jax.random.split(key)\n",
    "        self.out_conv = eqx.nn.ConvTranspose(\n",
    "            num_spatial_dims=dim,\n",
    "            in_channels=2*num_channels,\n",
    "            out_channels=num_out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=(kernel_size-1)//2,\n",
    "            stride=1,\n",
    "            key=init_key,\n",
    "        )\n",
    "        \n",
    "    def __call__(self, x):\n",
    "                \n",
    "        # Apply first convolution with non-linearity\n",
    "        x = jax.nn.relu(self.in_conv(x))\n",
    "        \n",
    "        # Apply UNet block\n",
    "        x = self.unet_block(x)\n",
    "        \n",
    "        # Apply last convolution without non-linearity\n",
    "        x = self.out_conv(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_value_and_grad\n",
    "def compute_loss(model, x):\n",
    "    y = jax.vmap(model)(x)\n",
    "    return jnp.mean(jnp.mean((y - x)**2., axis=(1, 2, 3)))\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(model, x, opt_state):\n",
    "    loss, grads = compute_loss(model, x)\n",
    "    updates, opt_state = optim.update(grads, opt_state)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return loss, model, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.config.set_visible_devices([], device_type=\"GPU\")\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "data_dir = \"/tmp/tfds\"\n",
    "\n",
    "mnist_data, info = tfds.load(name=\"mnist\", batch_size=-1, data_dir=data_dir, with_info=True)\n",
    "mnist_data = tfds.as_numpy(mnist_data)\n",
    "\n",
    "x_train = jnp.transpose(mnist_data[\"train\"][\"image\"], axes=(0, 3, 2, 1)) / 128. - 0.5\n",
    "x_test = jnp.transpose(mnist_data[\"test\"][\"image\"], axes=(0, 3, 2, 1)) / 128. - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1, 28, 28)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_depth = 2\n",
    "num_in_channels = 1\n",
    "num_out_channels = 1\n",
    "num_channels = 8\n",
    "kernel_size = 5\n",
    "dim = 2\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "input_shape = (num_in_channels,) + dim * (64,)\n",
    "inputs = jnp.ones(shape=input_shape)\n",
    "\n",
    "unet = UNet(\n",
    "    unet_depth=unet_depth,\n",
    "    num_in_channels=num_in_channels,\n",
    "    num_out_channels=num_out_channels,\n",
    "    num_channels=num_channels,\n",
    "    kernel_size=kernel_size,\n",
    "    dim=dim,\n",
    "    key=key,\n",
    ")\n",
    "\n",
    "jax.vmap(unet)(x_train[:16]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4661\n",
      "0.0134\n",
      "0.0075\n",
      "0.0038\n",
      "0.0024\n",
      "0.0021\n",
      "0.0012\n",
      "0.0010\n",
      "0.0014\n",
      "0.0011\n"
     ]
    }
   ],
   "source": [
    "optim = optax.adam(1e-3)\n",
    "opt_state = optim.init(unet)\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    key, rand_key = jax.random.split(key)\n",
    "    idx = jax.random.choice(rand_key, 60000, shape=(16,), replace=True)\n",
    "    loss, unet, opt_state = make_step(unet, x_train[idx], opt_state)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"{loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x167faebe0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(unet(x_test[100])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x168027860>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAOOklEQVR4nO3df5BV9XnH8c/DukAkbssK3e4ABmPQDmkN0S3YaDs6tlEpmdVp64TOWJzarM1oNda0cdJ2tO0f1WpMmp/OKhjMJNrMGCOpTivdJmUyNoTVEAQxQBFHmWW3QKZIDbDA0z/26Gxwz/eu95x7z4Xn/ZrZufee5557nrnDh3Pu+fU1dxeAU9+UqhsA0ByEHQiCsANBEHYgCMIOBHFaMxc21ab5dM1o5iKBUA7p/3TED9tEtUJhN7MrJf2TpDZJD7n73an3T9cMLbHLiywSQMJ6H8it1b0Zb2Ztkr4k6SpJCyUtN7OF9X4egMYq8pt9saQd7r7T3Y9IekxSbzltAShbkbDPkfTquNevZdN+jpn1mdmgmQ2O6nCBxQEoouF7492939173L2nXdMavTgAOYqEfbekeeNez82mAWhBRcK+QdICMzvbzKZK+qikNeW0BaBsdR96c/ejZnazpH/T2KG3Ve6+pbTOAJSq0HF2d39a0tMl9QKggThdFgiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxBEoSGbzWyXpNclHZN01N17ymgKQPkKhT1zmbvvLeFzADQQm/FAEEXD7pKeMbPnzKxvojeYWZ+ZDZrZ4KgOF1wcgHoV3Yy/xN13m9kvSVprZi+5+7rxb3D3fkn9ktRhnV5weQDqVGjN7u67s8cRSU9IWlxGUwDKV3fYzWyGmZ3x5nNJH5a0uazGAJSryGZ8l6QnzOzNz/mGu/9rKV0BKF3dYXf3nZI+UGIvABqIQ29AEIQdCIKwA0EQdiAIwg4EUcaFMEAl2madmawf27uvSZ2cHFizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQHGdHIW0dHcn6G5ecl1sbubA9Oe/Puo8m671Lnk/Wn/n2h3JrZ/3L/ybn9R9tSdZPRqzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIjrMjafS3L0zWD37yp8n6937tgbqXPUWWrD92cHayfu+frs+tHexLD0X2+9f/WbJ+2sBzyXorYs0OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0FwnP0Ut7fvN5L1T33yG8n6781IXzNeW/pYecqyK/4wWT+++aVkffSlttzadWfsSc7b9Xc7k/V9A8lyS6q5ZjezVWY2Ymabx03rNLO1ZrY9e5zZ2DYBFDWZzfivSrryhGl3SBpw9wWSBrLXAFpYzbC7+zpJ+0+Y3CtpdfZ8taSrS+4LQMnq/c3e5e5D2fM9krry3mhmfZL6JGm6Tq9zcQCKKrw33t1dkifq/e7e4+497ZpWdHEA6lRv2IfNrFuSsseR8loC0Aj1hn2NpBXZ8xWSniynHQCNYmNb4Yk3mD0q6VJJsyQNS7pT0rclfVPSWZJekXStu5+4E+9tOqzTl9jlBVuOp+3cc5L1oXvz77/+HxesSs7bMWV6sn48/xfapKw7NDW3dmv/jcl559zzbKFlb//iktzaT675cqHPXjYnfZ1/Vdb7gA74/glPbqi5g87dl+eUSC1wEuF0WSAIwg4EQdiBIAg7EARhB4LgEtcWcGjZ4mT9/i98MVk/f2r+pZwvH00fOtt//I1k/azT3pWs1/Kxp/4kt7ag4KG1Wmy0/strT0Ws2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCI6zN8G2L6ePoz98xUPJelfbkWR9xa6P5Nb23TY3Oe/f/3P6EtizklXpqTd+IVn/lTu35daO1fjson73N+sfVvmefe8vsZPWwJodCIKwA0EQdiAIwg4EQdiBIAg7EARhB4LgOHsJhm7/ULK+ozd9PfqGw+lrzq//o1uS9bbv5Q+r/PJj85LzXpi4Fl6qfSvpv3z8umT97J/+V7LeSB+Y8Wrd8z71D5cm6x36Qd2fXRXW7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBMfZJ2noz/OPpd/38QeT87ZZ+v/Uv77hj9PzJ46j13JsNH0cvVZvLx35WbL+vof2pJefrBZ00fnJ8rz2Lbm1hw+kzz+YuWE4WW/0tfiNUHPNbmarzGzEzDaPm3aXme02s43Z39LGtgmgqMlsxn9V0pUTTP+suy/K/p4uty0AZasZdndfJ2l/E3oB0EBFdtDdbGabss38mXlvMrM+Mxs0s8FRHS6wOABF1Bv2r0g6R9IiSUOSPpP3Rnfvd/ced+9p17Q6FwegqLrC7u7D7n7M3Y9LelBS+vapACpXV9jNrHvcy2skbc57L4DWUPM4u5k9KulSSbPM7DVJd0q61MwWSXJJuyTd2MAem2L4lvQ16Z+/6YHc2sXTR5Pznrfy5mR9/n/+MFkv4ry5NY4X+/FkfW6NfyGH5ncm6+07Xk5/QMKURQuT9YVfSq9jLnvXodzar3/+6uS8XTsaO3Z8FWqG3d2XTzB5ZQN6AdBAnC4LBEHYgSAIOxAEYQeCIOxAEGEucW0795xkfeVtn0vWz0/ccvmCH6Zvpzz/b6q7nfIb985J1v/gjiuS9Ufe+51k/Zf/dmeyvvXc/EOap+9NH/Z75N77kvXTLVnW+c9+PLc2f+WPk/OmOzs5sWYHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSDMPT0kb5k6rNOX2OUN+ey295+XrG+9pSNZ37Ys/xJWSfqLPUvy512avszz2PBIst7KZj/7i8n6w+8ZaNiyNx1J37D5Y/fcmqzPfqC68xuqst4HdMD3T3gGAmt2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQjilLme/ZXeM5P1bcu+kKy/fDT/tsOS9KO7LsitTR9u3K2gq7b/mqnJ+kW96dtkH5+af9H59H3pq8Y7Hv1Bsj5b8Y6jF8GaHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCOGWOsx/uTB+znaL0Tcavevz2ZP1930kf8z1V1boWf1b/yXutfjQ11+xmNs/MvmtmL5rZFjO7NZveaWZrzWx79jiz8e0CqNdkNuOPSrrd3RdKukjSTWa2UNIdkgbcfYGkgew1gBZVM+zuPuTuz2fPX5e0VdIcSb2SVmdvWy3p6kY1CaC4d/Sb3czmS/qgpPWSutx9KCvtkdSVM0+fpD5Jmq7T6+0TQEGT3htvZu+W9LikT7j7gfE1H7tr5YR3rnT3fnfvcfeedk0r1CyA+k0q7GbWrrGgf93dv5VNHjaz7qzeLYndskALq7kZb2YmaaWkre5+/7jSGkkrJN2dPT7ZkA4nadllg8n6bUP5t4KWpO5nm3dLbaAKk/nNfrGk6yS9YGYbs2mf1ljIv2lmN0h6RdK1jWkRQBlqht3dvy/lnpHSmBEfAJSO02WBIAg7EARhB4Ig7EAQhB0I4pS5xHXrhUcLzT9D60vqBGhNrNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiCImmE3s3lm9l0ze9HMtpjZrdn0u8xst5ltzP6WNr5dAPWazCARRyXd7u7Pm9kZkp4zs7VZ7bPufl/j2gNQlsmMzz4kaSh7/rqZbZU0p9GNASjXO/rNbmbzJX1QemuspJvNbJOZrTKzmTnz9JnZoJkNjupwoWYB1G/SYTezd0t6XNIn3P2ApK9IOkfSIo2t+T8z0Xzu3u/uPe7e065pJbQMoB6TCruZtWss6F93929JkrsPu/sxdz8u6UFJixvXJoCiJrM33iStlLTV3e8fN7173NuukbS5/PYAlGUye+MvlnSdpBfMbGM27dOSlpvZIkkuaZekGxvSIYBSTGZv/Pcl2QSlp8tvB0CjcAYdEARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCHP35i3M7H8kvTJu0ixJe5vWwDvTqr21al8SvdWrzN7e4+6zJyo0NexvW7jZoLv3VNZAQqv21qp9SfRWr2b1xmY8EARhB4KoOuz9FS8/pVV7a9W+JHqrV1N6q/Q3O4DmqXrNDqBJCDsQRCVhN7MrzewnZrbDzO6oooc8ZrbLzF7IhqEerLiXVWY2Ymabx03rNLO1ZrY9e5xwjL2KemuJYbwTw4xX+t1VPfx503+zm1mbpG2SfkfSa5I2SFru7i82tZEcZrZLUo+7V34Chpn9lqSDkh5x91/Npv2jpP3ufnf2H+VMd/9Ui/R2l6SDVQ/jnY1W1D1+mHFJV0u6XhV+d4m+rlUTvrcq1uyLJe1w953ufkTSY5J6K+ij5bn7Okn7T5jcK2l19ny1xv6xNF1Oby3B3Yfc/fns+euS3hxmvNLvLtFXU1QR9jmSXh33+jW11njvLukZM3vOzPqqbmYCXe4+lD3fI6mrymYmUHMY72Y6YZjxlvnu6hn+vCh20L3dJe5+gaSrJN2Uba62JB/7DdZKx04nNYx3s0wwzPhbqvzu6h3+vKgqwr5b0rxxr+dm01qCu+/OHkckPaHWG4p6+M0RdLPHkYr7eUsrDeM90TDjaoHvrsrhz6sI+wZJC8zsbDObKumjktZU0MfbmNmMbMeJzGyGpA+r9YaiXiNpRfZ8haQnK+zl57TKMN55w4yr4u+u8uHP3b3pf5KWamyP/H9L+qsqesjp672Sfpz9bam6N0mPamyzblRj+zZukHSmpAFJ2yX9u6TOFurta5JekLRJY8Hqrqi3SzS2ib5J0sbsb2nV312ir6Z8b5wuCwTBDjogCMIOBEHYgSAIOxAEYQeCIOxAEIQdCOL/AUVQLBz8T7+gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[100, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography} ./references.bib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-random-walks",
   "language": "python",
   "name": "venv-random-walks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
