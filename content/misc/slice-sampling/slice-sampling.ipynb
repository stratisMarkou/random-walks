{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice Sampling\n",
    "\n",
    "Slice sampling {cite}`neal2003slice` is a Markov Chain Monte Carlo (MCMC) method for sampling from unnormalised probability distributions, developed by Radford Neal. Similarly to all other MCMC methods, Slice Sampling starts out from an initial point $x_0$ and evolves this according to a rule $p(x_{n + 1} | x_n)$, such that the distribution of $x_n$ approaches $\\pi$ in the limit $n \\to \\infty$.\n",
    "\n",
    "The feature that makes Slice Sampling interesting is that it involves very few tunable parameters and virtually no critical design choices - unlike other sampling algorithms such as Metropolis Hastings, where the choice of proposal distribution can greatly affect the performance of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.d-flex {\n",
       "    display: none!important;\n",
       "}\n",
       "\n",
       ".bd-toc nav {\n",
       "    opacity: 1;\n",
       "    max-height: 100vh!important;\n",
       "}\n",
       "\n",
       ".bd-toc .nav .nav {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".prev-next-bottom {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".footer {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".navbar_footer {\n",
       "\tdisplay: none;\n",
       "}\n",
       "\n",
       ".definition {\n",
       "\tbackground-color: rgba(123, 183, 223, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(123, 183, 223, 0.5);\n",
       "}\n",
       "\n",
       ".theorem {\n",
       "\tbackground-color: rgba(240, 213, 75, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(240, 213, 75, 0.5);\n",
       "}\n",
       "\n",
       ".lemma {\n",
       "\tbackground-color: rgba(255, 218, 185, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(255, 218, 185, 0.5);\n",
       "}\n",
       "\n",
       ".observation {\n",
       "\tbackground-color: rgba(178, 234, 188, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(178, 234, 188, 0.5);\n",
       "}\n",
       "\n",
       "details.proof {\n",
       "    border-width: 2px;\n",
       "\tborder-radius: 20px;\n",
       "\tborder-style: solid;\n",
       "\tbackground-color: rgba(128, 128, 128, 0.2);\n",
       "\tborder-color: rgba(128, 128, 128, 0.1);\n",
       "}\n",
       "\n",
       "\n",
       "details.proof div{\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "}\n",
       "\n",
       "details.proof {\n",
       "\tpadding: 0px 30px 0px 30px;\n",
       "}\n",
       "\n",
       "summary {\n",
       "\tmargin-left: -32px;\n",
       "\tpadding-left: 15px;\n",
       "\tpadding-right: 15px;\n",
       "}\n",
       "\n",
       "summary + * {\n",
       "    margin-top: 10px;\n",
       "}\n",
       "\n",
       ".tag_center-output div img {\n",
       "    display:block;\n",
       "    margin:auto;\n",
       "}\n",
       "\n",
       ".container {\n",
       "\twidth : 103% !important;\n",
       "}\n",
       "\n",
       "details > .math.notranslate.nohighlight {\n",
       "\tmargin-top: -50px;\n",
       "\tmargin-bottom: -15px;\n",
       "}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML, set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "css_style = open('../../../_static/custom_style.css', 'r').read()\n",
    "HTML(f'<style>{css_style}</style>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Slice Sampling algorithm\n",
    "\n",
    "<div class='definition'>\n",
    "\n",
    "**Definition (One dimensional slice sampling)** Given an unnormalised target distribution $f(x)$ and an initial point $x_0$, slice sampling generates a new point $x_1$ as follows:\n",
    "    \n",
    "1. Sample $y \\sim \\text{Uniform}[0, f(x_0)]$. This defines the slice set $$S_y = \\{x : y = f(x)\\}.$$\n",
    "2. Generate a finite interval $I$ that contains $x_0$.\n",
    "3. Sample $x_1$ uniformly from the set of intervals $S_y \\cap I \\cap A$, where\n",
    "    \n",
    "$$A = \\{x_1 : p(x_1 | x_0, y) = p(x_0 | x_1, y)\\}.$$\n",
    "    \n",
    "We write $p(x_1 | x_0)$ for the probability distribution of the new point $x_1$, conditioned on the previous point $x_0$.\n",
    "    \n",
    "</div>\n",
    "<br>\n",
    "    \n",
    "For the second step of the above algorithm, Neal presents two expansion methods for generating $I$, the step-out method and the doubling method. For the third step, he shows that sampling from $S_y \\cap I \\cap A$ can be carried out efficiently. We'll look at the step-out and the doubling methods in more detail and provide proofs of the related results.\n",
    "\n",
    "Note also that the above algorithm is a special case of the more general \"crumb\" framework.{cite}`neal2003slice` Crumb-based slice sampling is not constained to generating an $I$ and sampling from a subset of it, although methods that do so can be cast as crumb-based methods. Crumb-based methods are very general and therefore ammeanable to a great deal of tuning and design choices, which are beyond the scope of this page, so we won't look into them.\n",
    "\n",
    "It can be shown that the sampling algorithm defined above leaves the target distribution invariant. To show this, it is enough to show that slice sampling satisfies detailed balance.\n",
    "\n",
    "<div class='lemma'>\n",
    "\n",
    "**Result (Slice sampling satisfies detailed balance)** The slice-sampling transition rule satisfies detailed balance\n",
    "    \n",
    "$$\\begin{align}\n",
    "p(x_1 | x_0) \\pi(x_0) = p(x_0 | x_1) \\pi(x_1).\n",
    "\\end{align}$$\n",
    "    \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "\n",
    "<details class=\"proof\">\n",
    "<summary> Slice sampling satisfies detailed balance </summary>\n",
    "\n",
    "We will show that slice sampling satisfies detailed balance of the target distribution. We have\n",
    "$$\\begin{align}\n",
    "p(x_1 | x_0)\\pi(x_0) &= \\int_0^{\\pi(x_0)} p(x_1 | x_0, y) p(y | x_0) \\pi(x_0) dy \\\\\n",
    "                     &= \\int_0^{\\pi(x_0)} p(x_1 | x_0, y) \\frac{1}{\\pi(x_0)} \\pi(x_0) dy \\\\\n",
    "                     &= \\int_0^{\\min(\\pi(x_0), \\pi(x_1))} p(x_1 | x_0, y) dy,\n",
    "\\end{align}$$\n",
    "where in the last line we have used the fact that\n",
    "$$\\begin{align}\n",
    "p(x_1 | x_0, y) = 0, \\text{ whenever } y > \\pi(x_1).\n",
    "\\end{align}$$\n",
    "    \n",
    "Similarly, going the other way we have\n",
    "$$\\begin{align}\n",
    "p(x_0 | x_1)\\pi(x_1) &= \\int_0^{\\pi(x_1)} p(x_0 | x_1, y) p(y | x_1) \\pi(x_1) dy \\\\\n",
    "                     &= \\int_0^{\\pi(x_1)} p(x_0 | x_1, y) \\frac{1}{\\pi(x_1)} \\pi(x_1) dy \\\\\n",
    "                     &= \\int_0^{\\min(\\pi(x_0), \\pi(x_1))} p(x_0 | x_1, y) dy.\n",
    "\\end{align}$$\n",
    "Therefore, we only need to show that\n",
    "$$\\begin{align}\n",
    "p(x_1 | x_0, y) &= p(x_0 | x_1, y) dy,\n",
    "\\end{align}$$\n",
    "which is follows by the definition of $A$, that is\n",
    "$$A = \\{x_1 : p(x_1 | x_0, y) = p(x_0 | x_1, y)\\}.$$\n",
    "This proof in offloads a bit of the work to finding a way to ensure that $x$ lies not only in $S_y \\cap I$ but also in $A$. We discuss this later.\n",
    "    \n",
    "</details>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval-expansion methods\n",
    "\n",
    "Neal proposes two methods for computing the finite interval $I$: the step-out method and the doubling method. We discuss each in turn.\n",
    "\n",
    "### Step-out method\n",
    "\n",
    "<div class='definition'>\n",
    "\n",
    "**Definition (Step-out method)** Given $f, x_0, y$, positive integer $m$ and positive real $w > 0$, the step-out method produces an interval $I = [L, R]$ containing $x_0$ as follows\n",
    "    \n",
    "1. Sample $U, V \\sim \\text{Uniform}[0, 1]$.\n",
    "2. Initialise endpoints $L = x_0 - wU$ and $R = x_0 + w$, and budgets $N_L = \\text{floor}(mV)$ and $N_R = (m - 1) - N_L$.\n",
    "3. While $N_L > 0$ and $y \\leq f(L)$ update $L \\leftarrow L - w$, $N_L \\leftarrow N_L - 1$.\n",
    "4. While $N_R > 0$ and $y \\leq f(R)$ update $R \\leftarrow R + w$, $N_R \\leftarrow N_R - 1$.\n",
    "    \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "This process expands $I$ to the left and to the right, terminating the expansion in each direction when it finds an endpoint outside the slice, or when the budget is used up. Selecting $U, V$ at random is of crucial importance in ensuring that the resulting $A$ is not too restrictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_out_expansion(x0, y, log_prob, w, m):\n",
    "    \n",
    "    U = np.random.rand()\n",
    "    L = x0 - w * U\n",
    "    R = L + w\n",
    "    \n",
    "    Lhist = [L]\n",
    "    Rhist = [R]\n",
    "    \n",
    "    J = np.floor(m * np.random.rand())\n",
    "    K = m - 1 - J\n",
    "    \n",
    "    fL = log_prob(L)\n",
    "    fR = log_prob(R)\n",
    "    \n",
    "    while J > 0 and y <= fL:\n",
    "        \n",
    "        L = L - w\n",
    "        J = J - 1\n",
    "        fL = log_prob(L)\n",
    "        \n",
    "        Lhist.append(L)\n",
    "        \n",
    "    while K > 0 and y <= fR:\n",
    "        \n",
    "        R = R + w\n",
    "        K = K - 1\n",
    "        fR = log_prob(R)\n",
    "        \n",
    "        Rhist.append(R)\n",
    "        \n",
    "    return L, R, (Lhist, Rhist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doubling method\n",
    "\n",
    "<div class='definition'>\n",
    "\n",
    "**Definition (Doubling method)** Given $f, x_0, y$, positive integer $p$ and positive real $w > 0$, the step-out method produces an interval $I = [L, R]$ containing $x_0$, as follows\n",
    "    \n",
    "1. Sample $U \\sim \\text{Uniform}[0, 1]$.\n",
    "2. Initialise endpoints $L = x_0 - wU$ and $R = x_0 + w$ and budget $K = p$.\n",
    "3. While $K > 0$ and $(y < f(L) \\text{ or } y < f(R))$, sample $V \\sim \\text{Uniform}[0, 1]$ and update \n",
    "    \n",
    "    $$\\begin{align}\n",
    "L \\leftarrow L - (R - L) &&\\text{ if } V < \\frac{1}{2} \\\\\n",
    "R \\leftarrow R + (R - L) &&\\text{ otherwise}.\n",
    "\\end{align}$$\n",
    "    \n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_expansion(x0, y, log_prob, w, p):\n",
    "    \n",
    "    U = np.random.unform()\n",
    "    L = x0 - w * U\n",
    "    R = L + w\n",
    "    K = p\n",
    "    \n",
    "    Lhist = [L]\n",
    "    Rhist = [R]\n",
    "    \n",
    "    fL = log_prob(L)\n",
    "    fR = log_prob(R)\n",
    "    \n",
    "    while K > 0 and (fL > y or fR > y):\n",
    "        \n",
    "        V = np.random.uniform()\n",
    "        \n",
    "        if V > 0.5:\n",
    "            L = L - (R - L)\n",
    "            fL = log_prob(L)\n",
    "            \n",
    "        else:\n",
    "            R = R + (R - L)\n",
    "            fR = log_prob(R)\n",
    "        \n",
    "        Lhist.append(L)\n",
    "        Rhist.append(R)\n",
    "        \n",
    "        K = K - 1\n",
    "            \n",
    "    return L, R, (Lhist, Rhist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval sampling\n",
    "\n",
    "### Sampling method\n",
    "\n",
    "<div class='lemma'>\n",
    "\n",
    "**Result (Acceptable sets for step-out/doubling methods)** Starting from the point $x_0$, the acceptable set\n",
    "    \n",
    "$$A = \\{x_1 : p(x_1 | x_0, y) = p(x_0 | x_1, y)\\}$$\n",
    "    \n",
    "is equal to $S \\cap I$ for the step-out method, where $I$ is the interval expanded from $x_0$ using parameters $w, p$. For the doubling method, we can determine whether a candidate point $x_1$ is in the acceptable set defined by $x_0, y, w, p, I$ as follows\n",
    "    \n",
    "1. Initialise $[L, R] = I$.\n",
    "2. While $R - L > w$ repeat\n",
    "\n",
    "    2.1 Set $M = (L + R)~/~2$, and update $L, R$ according to\n",
    "    \n",
    "    $$\\begin{align}\n",
    "L \\leftarrow M &&\\text{ if } M \\geq x_0 \\\\\n",
    "R \\leftarrow M &&\\text{ otherwise}.\n",
    "\\end{align}$$\n",
    "    \n",
    "    2.2 If $y \\geq f(L)$ and $y \\geq f(R)$, $x$ is not acceptable.\n",
    "3. If $x$ is not rejected in the above loop, it is acceptable.\n",
    "    \n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_acceptable_set(x0, y, L, R, log_prob, method, params, shrinkage):\n",
    "    \n",
    "    L0, R0 = L, R\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        x = L + (R - L) * np.random.rand()\n",
    "        \n",
    "        accept = is_acceptable(x, y, L0, R0, log_prob, method, params)\n",
    "        \n",
    "        if accept:\n",
    "            return x\n",
    "        \n",
    "        elif shrinkage and x < x0:\n",
    "            L = x\n",
    "            \n",
    "        elif shrinkage and x > x0:\n",
    "            R = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for acceptibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_acceptable(x, y, L, R, log_prob, method, params):\n",
    "    \n",
    "    # Function value at candidate point\n",
    "    f = log_prob(x)\n",
    "    \n",
    "    # For stepping out, check x is in the slice (y < f)\n",
    "    if method == 'step_out':\n",
    "        \n",
    "        if y <= f:\n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    # For doubling, check the doubling sequence can be recreated the other way\n",
    "    elif method == 'double':\n",
    "        \n",
    "        w, p = params\n",
    "        \n",
    "        fx = log_prob(x)\n",
    "        \n",
    "        while R - L > 1.5 * w:\n",
    "            \n",
    "            M = (R + L) / 2\n",
    "            \n",
    "            fL = log_prob(L)\n",
    "            fM = log_prob(M)\n",
    "            fR = log_prob(R)\n",
    "            \n",
    "            if x >= M and (y < fM or y < fR): L = M\n",
    "                \n",
    "            elif x < M and (y < fL or y < fM): R = M\n",
    "            \n",
    "            else: return False\n",
    "            \n",
    "        # If the point is not rejcected in the loop, it is acceptable\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Slice Sampling algorithm\n",
    "\n",
    "Putting it all together, we have a complete MCMC algorithm for sampling from $1$-dimensional distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x0, log_prob, method, params, shrinkage):\n",
    "    \n",
    "    f0 = log_prob(x0)\n",
    "    y = np.log(np.exp(f0) * np.random.rand())\n",
    "    \n",
    "    L = None\n",
    "    R = None\n",
    "    \n",
    "    if method == 'step_out':\n",
    "        w, m = params\n",
    "        L, R, _ = step_out_expansion(x0, y, log_prob, w, m)\n",
    "        \n",
    "    elif method == 'double':\n",
    "        w, p = params\n",
    "        L, R, _ = double_expansion(x0, y, log_prob, w, p)\n",
    "        \n",
    "    x = sample_acceptable_set(x0=x0,\n",
    "                              y=y,\n",
    "                              L=L,\n",
    "                              R=R,\n",
    "                              log_prob=log_prob,\n",
    "                              method=method,\n",
    "                              params=params,\n",
    "                              shrinkage=shrinkage)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography} ./references.bib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-random-walks",
   "language": "python",
   "name": "venv-random-walks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
