{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice Sampling\n",
    "\n",
    "Slice Sampling {cite}`neal2003slice` is a Markov Chain Monte Carlo (MCMC) method for sampling from unnormalised probability distributions. Like any other MCMC method, Slice Sampling starts out from an initial point $x_n$ and evolves this according to a stochastic transition rule, $p(x_{n + 1} | x_n)$, such that the distribution of $x_n$ approaches a target distribution in the limit $n \\to \\infty$.\n",
    "\n",
    "Unlike many other MCMC methods, Slice Sampling has two very nice features which make it interesting. First, it involves very few tunable parameters and is relatively robust to different settings of these parameters. This is typically not so for other MCMC methods such as simple Metropolis Hastings, where the choice of proposal distribution can greatly affect the performance of the algorithm. The second feature, which is related to the first, is that Slice Sampling is adaptive. The Slice Sampling transition rule adapts to the shape of the distribution at the region it is trying to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.d-flex {\n",
       "    display: none!important;\n",
       "}\n",
       "\n",
       ".bd-toc nav {\n",
       "    opacity: 1;\n",
       "    max-height: 100vh!important;\n",
       "}\n",
       "\n",
       ".bd-toc .nav .nav {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".prev-next-bottom {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".footer {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".navbar_footer {\n",
       "\tdisplay: none;\n",
       "}\n",
       "\n",
       ".definition {\n",
       "\tbackground-color: rgba(123, 183, 223, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(123, 183, 223, 0.5);\n",
       "}\n",
       "\n",
       ".theorem {\n",
       "\tbackground-color: rgba(240, 213, 75, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(240, 213, 75, 0.5);\n",
       "}\n",
       "\n",
       ".lemma {\n",
       "\tbackground-color: rgba(255, 218, 185, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(255, 218, 185, 0.5);\n",
       "}\n",
       "\n",
       ".observation {\n",
       "\tbackground-color: rgba(178, 234, 188, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(178, 234, 188, 0.5);\n",
       "}\n",
       "\n",
       "details.proof {\n",
       "    border-width: 2px;\n",
       "\tborder-radius: 20px;\n",
       "\tborder-style: solid;\n",
       "\tbackground-color: rgba(128, 128, 128, 0.2);\n",
       "\tborder-color: rgba(128, 128, 128, 0.1);\n",
       "}\n",
       "\n",
       "\n",
       "details.proof div{\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "}\n",
       "\n",
       "details.proof {\n",
       "\tpadding: 0px 30px 0px 30px;\n",
       "}\n",
       "\n",
       "summary {\n",
       "\tmargin-left: -32px;\n",
       "\tpadding-left: 15px;\n",
       "\tpadding-right: 15px;\n",
       "}\n",
       "\n",
       "summary + * {\n",
       "    margin-top: 10px;\n",
       "}\n",
       "\n",
       ".tag_center-output div img {\n",
       "    display:block;\n",
       "    margin:auto;\n",
       "}\n",
       "\n",
       ".container {\n",
       "\twidth : 103% !important;\n",
       "}\n",
       "\n",
       "details > .math.notranslate.nohighlight {\n",
       "\tmargin-top: -50px;\n",
       "\tmargin-bottom: -15px;\n",
       "}\n",
       "\n",
       "\n",
       ".center {\n",
       "  display: block;\n",
       "  margin-left: auto;\n",
       "  margin-right: auto;\n",
       "}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML, set_matplotlib_formats\n",
    "from IPython.display import Image\n",
    "\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "css_style = open('../../../_static/custom_style.css', 'r').read()\n",
    "HTML(f'<style>{css_style}</style>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idealised Slice Sampling\n",
    "\n",
    "Slice Sampling is based on the observation that sampling a point $(x, y)$ (where $x \\in \\mathbb{R}^D, y\\in \\mathbb{R}$) uniformly from the area under an unnormalised probability density function $f(x)$, and discarding the vertical $y$ coordinate, yields an exact sample $x \\sim \\pi(x) \\propto f(x)$, where $\\pi$ is the normalised version of $f$. This is illustrated in the image below. In order to sample from the Gaussian on the (left), we sample points uniformly at random from the area under its unnormalised density $f(x)$ (middle). The resulting points are exact samples from the normalised Gaussian (right).\n",
    "\n",
    "![./img/motivating.png](./img/motivating.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stating the problem this way has not made it any easier, because sampling $(x, y)$ from the area under the curve is just as hard as sampling $\\pi(x)$ itself. We can make progress by observing that we can define a Markov Chain in this augmented $(x, y)$ space and set it up so that this augmented chain converges to a uniform in the area under $f(x)$ - this is in contrast to conventional MCMC algorithms which work in $x$-space only.\n",
    "\n",
    "Here is how we can set up this chain. Given an initial point $x_n$ (dashed line in the image below) we can generate the next point $x_{n+1}$ by first sampling\n",
    "\n",
    "$$y \\sim \\text{Uniform}[0, f(x_n)].$$\n",
    "\n",
    "This gives a point $(x_n, y)$ in the augmented space, shown as a black point, whose $y$-coordinate defines a *slice* set\n",
    "\n",
    "$$S_y = \\{x : y = f(x)\\},$$\n",
    "\n",
    "shown as a thick black line. We can sample a point uniformly at random from this slice\n",
    "\n",
    "$$x_{n+1} \\sim \\text{Uniform}[S_y],$$\n",
    "\n",
    "to obtain a new point $(x_{n+1}, y)$, shown as the green point. Lastly, by discarding the $y$ coordinate, we are left with a new point $x_{n+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "center-output",
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(\"./img/idealised.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transition procedure leaves the target distribution invariant. Furthermore, if the target distribution is positive everywhere, the resulting Markov Chain is guaranteed to converge to it. This is illustrated for the Gaussian example below.\n",
    "\n",
    "![./img/5.png](./img/5.png)\n",
    "![./img/1000.png](./img/1000.png)\n",
    "\n",
    "However, the issue with this algorithm is that in general, there is no straightforward way to sample from $S_y$. The slice $S_y$ is a union of intervals, each of which has endpoints corresponding to solutions of the equation $y = f(x)$, for which there may not be a closed form. In addition, the slice is not guaranteed to be bounded, as it could be for example a union of ever-smaller and ever far apart intervals, whose union is unbounded. The Slice Sampling alogorithm below circumvents both these issues.\n",
    "\n",
    "Although Slice Sampling can be applied to random variables of any dimension, applying it to high-dimensional distributions presents important issues. For the moment, we focus on the one-dimensional case $D = 1$, keeping in mind that the same ideas can be directly applied to $D > 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Slice Sampling algorithm\n",
    "\n",
    "To deal with the aforementioned issues, Slice Sampling defines a finite interval $I$ and a set $A$ and samples the new point $x_{n+1}$ uniformly from $S_y \\cap I \\cap A$ instead of $S_y$ - the definition and role of the set $A$ will be clarified shortly. Since the interval $I$ is finite, so will be the above intersection. This deals with the problem of boundedness of the set we are sampling from. Now in order to deal with the issue that the slice is not available in closed form, we can simply draw repeated samples from $I$ until one falls in $S_y \\cap A$. This accepted sample will be a uniform sample from $S_y \\cap I \\cap A$.\n",
    "\n",
    "Depending on the choice of $I$, an appropriately chosen set $A$ is needed in order to ensure that Slice Sampling leaves the target distribution invariant. Specifically, $A$ is defined as\n",
    "\n",
    "$$A = \\{x_{n+1} : p(x_{n+1} | x_n, y) = p(x_n | x_{n+1}, y)\\},$$\n",
    "\n",
    "that is the set for which transitions $(x_n, y) \\to (x_{n+1}, y)$ has the same probablity as transitions $(x_{n+1}, y) \\to (x_n, y)$. For example, in the case of idealised Slice Sampling (where $I = \\mathbb{R}$) the transition $(x_n, y) \\to (x_{n+1}, y)$ has the same probablity as the transition $(x_{n + 1}, y) \\to (x_{n}, y)$, so $A = S_y \\cap I$. However, if $I \\neq \\mathbb{R}$ we may have to adjust $A$ appropriately.\n",
    "\n",
    "There are several possible ways to define the set $I$. Here we will have a look at two methods proposed by by Neal. For these two choices, we won't have $A$ in closed form, but we can determine whether a point $x_{n+1}$ is in $A$ in a computationally cheap way. In summary, here is the full Slice sampling algorithm for one dimension.\n",
    "\n",
    "<div class='definition'>\n",
    "\n",
    "**Definition (One dimensional slice sampling)** Given an unnormalised target distribution $f(x)$ and a current point $x_n$, slice sampling generates a new point $x_{n+1}$ as follows:\n",
    "    \n",
    "1. Sample $y \\sim \\text{Uniform}[0, f(x_{n})]$. This defines the slice set $S_y = \\{x : y = f(x)\\}.$\n",
    "2. Generate a finite interval $I$ that contains $x_{n}$.\n",
    "3. Sample $x_{n+1}$ uniformly from the set of intervals $S_y \\cap I \\cap A$, where\n",
    "    \n",
    "$$A = \\{x_{n+1} : p(x_{n+1} | x_n, y) = p(x_n | x_{n+1}, y)\\}.$$\n",
    "    \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "It can be shown that the sampling algorithm defined above leaves the target distribution invariant. To show this, it is enough to show that slice sampling satisfies detailed balance.\n",
    "\n",
    "<div class='lemma'>\n",
    "\n",
    "**Result (Slice sampling satisfies detailed balance)** The slice-sampling transition rule satisfies detailed balance\n",
    "    \n",
    "$$\\begin{align}\n",
    "p(x_{n+1} | x_n) \\pi(x_n) = p(x_n | x_{n+1}) \\pi(x_{n+1}).\n",
    "\\end{align}$$\n",
    "    \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "\n",
    "<details class=\"proof\">\n",
    "<summary> Proof: Slice sampling satisfies detailed balance </summary>\n",
    "\n",
    "We will show that slice sampling satisfies detailed balance of the target distribution. We have\n",
    "    \n",
    "$$\\begin{align}\n",
    "p(x_{n+1} | x_n)\\pi(x_n) &= \\int_0^{\\pi(x_n)} p(x_{n+1} | x_n, y) p(y | x_n) \\pi(x_n) dy \\\\\n",
    "                     &= \\int_0^{\\pi(x_n)} p(x_{n+1} | x_n, y) \\frac{1}{\\pi(x_n)} \\pi(x_n) dy \\\\\n",
    "                     &= \\int_0^{\\min(\\pi(x_n), \\pi(x_{n+1}))} p(x_{n+1} | x_n, y) dy,\n",
    "\\end{align}$$\n",
    "    \n",
    "where in the last line we have used the fact that\n",
    "\n",
    "$$\\begin{align}\n",
    "p(x_{n+1} | x_n, y) = 0, \\text{ whenever } y > \\pi(x_{n+1}).\n",
    "\\end{align}$$\n",
    "    \n",
    "Similarly, going the other way we have\n",
    "\n",
    "$$\\begin{align}\n",
    "p(x_n | x_{n+1})\\pi(x_{n+1}) &= \\int_0^{\\pi(x_{n+1})} p(x_n | x_{n+1}, y) p(y | x_{n+1}) \\pi(x_{n+1}) dy \\\\\n",
    "                     &= \\int_0^{\\pi(x_{n+1})} p(x_n | x_{n+1}, y) \\frac{1}{\\pi(x_{n+1})} \\pi(x_{n+1}) dy \\\\\n",
    "                     &= \\int_0^{\\min(\\pi(x_n), \\pi(x_{n+1}))} p(x_n | x_{n+1}, y) dy.\n",
    "\\end{align}$$\n",
    "    \n",
    "Therefore, we only need to show that\n",
    "\n",
    "$$\\begin{align}\n",
    "p(x_{n+1} | x_n, y) &= p(x_n | x_{n+1}, y),\n",
    "\\end{align}$$\n",
    "\n",
    "which is follows by the definition of $A$. In particular, since $x_{n+1}$ is sampled from $S_y \\cap A \\cap I$, it will be in $A$. Since $A$ is defined as\n",
    "\n",
    "$$A = \\{x_{n+1} : p(x_{n+1} | x_n, y) = p(x_n | x_{n+1}, y)\\},$$\n",
    "\n",
    "it follows that $p(x_{n+1} | x_n, y) = p(x_n | x_{n+1}, y)$. This proof in offloads a bit of the work to the definition of $A$, which we will discuss shortly.\n",
    "    \n",
    "</details>\n",
    "<br>\n",
    "\n",
    "Note also that the above algorithm is a special case of the more general \"crumb\" framework.{cite}`neal2003slice` Crumb-based slice sampling is not constained to generating an $I$ and sampling from a subset of it, although methods that do so can be cast as crumb-based methods. Crumb-based methods are very general and therefore ammeanable to a great deal of tuning and design choices, which are beyond the scope of this page, so we won't look into them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the interval $I$\n",
    "\n",
    "We could define $I$ to be a constant-size interval and use this throughout the run of the chain. However, if our choice of $I$ is small compared to the lengthscale of $\\pi$, the chain will move slowly - slower than what it could if $I$ was larger. Similarly, if $I$ is too large, we may end up drawing several samples from $I$ until we draw an accpetable point (that is a point in $S_y \\cap A$). Lastly, the appropriate size of $I$ may be different for different regions of the target distribution. Therefore, the best solution would be have $I$ adapt to the distribution. Neal proposes{cite}`neal2003slice` two methods to produce adaptive intervals $I$: the step-out method and the doubling method. We will discuss each in turn.\n",
    "\n",
    "### Step-out method\n",
    "\n",
    "Starting from an interval $I = [L, R]$ of initial width $w = (R - L)$ containing $x_n$, we could expand it to the left in steps of $w$ until the left endpoint is outside the slice or until a maximum expansion budget $N_L$ is reached. We can repeat this expansion to the right with a corresponding budget $N_R$. The resulting interval $I$ contains $x_n$ and (hopefully) a considerable part of the slice $S_y$. There remains the question of how to choose the initial $L$ and $R$. Neal chooses to set{cite}`neal2003slice` $L$ and $R$ uniformly at random, such that $[L, R]$ contains $x_n$. We will show that in this case $A = S_y \\cap I$.\n",
    "\n",
    "![./img/stepout-full.png](./img/stepout-full.png)\n",
    "\n",
    "The step-out procedure is illustrated in the image above. Starting from the black cross, we sample the initial endpoints of the interval - the innermost blue and red crosses, as well as the expansion budgets. We then step out to the left and to the right until a point outside the slice is reached. After expanding to the left and to the right we are left with the interval $I$ - the solid horizontal line.\n",
    "\n",
    "<div class='definition'>\n",
    "\n",
    "**Definition (Step-out method)** Given $f, x_n, y$, positive integer $m$ and positive real $w > 0$, the step-out method produces an interval $I = [L, R]$ containing $x_n$ as follows\n",
    "    \n",
    "1. Sample $U, V \\sim \\text{Uniform}[0, 1]$.\n",
    "2. Initialise endpoints $L = x_n - wU$ and $R = x_n + w$, and budgets $N_L = \\lfloor mV\\rfloor$ and $N_R = (m - 1) - N_L$.\n",
    "3. While $N_L > 0$ and $y \\leq f(L)$ update $L \\leftarrow L - w$, $N_L \\leftarrow N_L - 1$.\n",
    "4. While $N_R > 0$ and $y \\leq f(R)$ update $R \\leftarrow R + w$, $N_R \\leftarrow N_R - 1$.\n",
    "    \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<details class=\"proof\">\n",
    "<summary> Proof: \\(A = S_y \\cap I\\) for the step-out method</summary>\n",
    "\n",
    "Suppose that starting from $(x_n, y)$, we sample $U$ and $N_L$ as specified above, that is\n",
    "    \n",
    "$$\\begin{align}\n",
    "U &\\sim \\text{Uniform}[0, 1], \\\\\n",
    "N_L &\\sim \\text{Uniform}\\{0, 1, ..., m - 1\\}.\n",
    "\\end{align}$$\n",
    "    \n",
    "The initial interval prior to expansion is $I_0 = [x_n - wU, x_n + w (1 - U)]$. Now suppose we apply the step out method to obtain the expanded interval $I$ and then sample $x_{n+1} \\sim \\text{Unifrom}[S_y \\cap I]$. Since $x_{n+1} \\in I$, the point $x_{n+1}$ is contained in an interval of width $w$ which was added onto $I$ while expanding it, that is\n",
    "    \n",
    "$$x_{n+1} \\in I_0' = [x_n + w(k - U), x_n + w (k + 1 + U)]$$\n",
    "    \n",
    "for some $- N_L \\leq k \\leq N_R - 1$. Now, starting from $(x_{n+1}, y)$ there exists a unique $U' \\in [0, 1]$ such that the initial interval is equal to $I_0'$\n",
    "    \n",
    "$$I_0' = [x_{n + 1} - wU', x_{n + 1} + (1 - w) U'], \\text{ for some unique } U' \\in [0, 1].$$\n",
    "    \n",
    "Now, expanding $I_0'$ from $(x_{n+1}, y)$ will result in the same interval endpoints as when expanding $I_0$ from $(x_n, y)$ except if the $I_0'$ expansion is stopped by the budget. But since $x_{n+1} \\in I_0'$, there exist budgets $N_L' \\in \\{0, 1, ..., m - 1\\}$ which will result in expanding $I_0'$ to obtain exactly $I$. The number of distinct budgets $N_L$ which will result in expanding $I_0$ to $I$ and the number of distinct budgets $N_L'$ which will result in expanding $I_0'$ to $I$, are the same. Therefore, the probability of starting from $(x_n, y)$ and transitioning to $(x_{n+1}, y)$ is the same as the other way around and thus $A = S_y \\cap I$.\n",
    "    \n",
    "</details>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_out_expansion(x0, y, log_prob, w, m):\n",
    "    \n",
    "    U = np.random.rand()\n",
    "    L = x0 - w * U\n",
    "    R = L + w\n",
    "    \n",
    "    Lhist = [L]\n",
    "    Rhist = [R]\n",
    "    \n",
    "    J = np.floor(m * np.random.rand())\n",
    "    K = m - 1 - J\n",
    "    \n",
    "    fL = log_prob(L)\n",
    "    fR = log_prob(R)\n",
    "    \n",
    "    while J > 0 and y <= fL:\n",
    "        \n",
    "        L = L - w\n",
    "        J = J - 1\n",
    "        fL = log_prob(L)\n",
    "        \n",
    "        Lhist.append(L)\n",
    "        \n",
    "    while K > 0 and y <= fR:\n",
    "        \n",
    "        R = R + w\n",
    "        K = K - 1\n",
    "        fR = log_prob(R)\n",
    "        \n",
    "        Rhist.append(R)\n",
    "        \n",
    "    return L, R, (Lhist, Rhist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doubling method\n",
    "\n",
    "<div class='definition'>\n",
    "\n",
    "**Definition (Doubling method)** Given $f, x_n, y$, positive integer $p$ and positive real $w > 0$, the step-out method produces an interval $I = [L, R]$ containing $x_n$, as follows\n",
    "    \n",
    "1. Sample $U \\sim \\text{Uniform}[0, 1]$.\n",
    "2. Initialise endpoints $L = x_n - wU$ and $R = x_n + w$ and budget $K = p$.\n",
    "3. While $K > 0$ and $(y < f(L) \\text{ or } y < f(R))$, sample $V \\sim \\text{Uniform}[0, 1]$ and update \n",
    "    \n",
    "    $$\\begin{align}\n",
    "L \\leftarrow L - (R - L) &&\\text{ if } V < \\frac{1}{2} \\\\\n",
    "R \\leftarrow R + (R - L) &&\\text{ otherwise}.\n",
    "\\end{align}$$\n",
    "    \n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_expansion(x0, y, log_prob, w, p):\n",
    "    \n",
    "    U = np.random.unform()\n",
    "    L = x0 - w * U\n",
    "    R = L + w\n",
    "    K = p\n",
    "    \n",
    "    Lhist = [L]\n",
    "    Rhist = [R]\n",
    "    \n",
    "    fL = log_prob(L)\n",
    "    fR = log_prob(R)\n",
    "    \n",
    "    while K > 0 and (fL > y or fR > y):\n",
    "        \n",
    "        V = np.random.uniform()\n",
    "        \n",
    "        if V > 0.5:\n",
    "            L = L - (R - L)\n",
    "            fL = log_prob(L)\n",
    "            \n",
    "        else:\n",
    "            R = R + (R - L)\n",
    "            fR = log_prob(R)\n",
    "        \n",
    "        Lhist.append(L)\n",
    "        Rhist.append(R)\n",
    "        \n",
    "        K = K - 1\n",
    "            \n",
    "    return L, R, (Lhist, Rhist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interval sampling\n",
    "\n",
    "### Sampling method\n",
    "\n",
    "<div class='lemma'>\n",
    "\n",
    "**Result (Acceptable sets for step-out/doubling methods)** Starting from the point $x_n$, the acceptable set\n",
    "    \n",
    "$$A = \\{x_{n+1} : p(x_{n+1} | x_n, y) = p(x_n | x_{n+1}, y)\\}$$\n",
    "    \n",
    "is equal to $S \\cap I$ for the step-out method, where $I$ is the interval expanded from $x_n$ using parameters $w, p$. For the doubling method, we can determine whether a candidate point $x_{n+1}$ is in the acceptable set defined by $x_n, y, w, p, I$ as follows\n",
    "    \n",
    "1. Initialise $[L, R] = I$.\n",
    "2. While $R - L > w$ repeat\n",
    "\n",
    "    2.1 Set $M = (L + R)~/~2$, and update $L, R$ according to\n",
    "    \n",
    "    $$\\begin{align}\n",
    "L \\leftarrow M &&\\text{ if } M \\geq x_n \\\\\n",
    "R \\leftarrow M &&\\text{ otherwise}.\n",
    "\\end{align}$$\n",
    "    \n",
    "    2.2 If $y \\geq f(L)$ and $y \\geq f(R)$, $x$ is not acceptable.\n",
    "3. If $x$ is not rejected in the above loop, it is acceptable.\n",
    "    \n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_acceptable_set(x0, y, L, R, log_prob, method, params, shrinkage):\n",
    "    \n",
    "    L0, R0 = L, R\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        x = L + (R - L) * np.random.rand()\n",
    "        \n",
    "        accept = is_acceptable(x, y, L0, R0, log_prob, method, params)\n",
    "        \n",
    "        if accept:\n",
    "            return x\n",
    "        \n",
    "        elif shrinkage and x < x0:\n",
    "            L = x\n",
    "            \n",
    "        elif shrinkage and x > x0:\n",
    "            R = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for acceptibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_acceptable(x, y, L, R, log_prob, method, params):\n",
    "    \n",
    "    # Function value at candidate point\n",
    "    f = log_prob(x)\n",
    "    \n",
    "    # For stepping out, check x is in the slice (y < f)\n",
    "    if method == 'step_out':\n",
    "        \n",
    "        if y <= f:\n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    # For doubling, check the doubling sequence can be recreated the other way\n",
    "    elif method == 'double':\n",
    "        \n",
    "        w, p = params\n",
    "        \n",
    "        fx = log_prob(x)\n",
    "        \n",
    "        while R - L > 1.5 * w:\n",
    "            \n",
    "            M = (R + L) / 2\n",
    "            \n",
    "            fL = log_prob(L)\n",
    "            fM = log_prob(M)\n",
    "            fR = log_prob(R)\n",
    "            \n",
    "            if x >= M and (y < fM or y < fR): L = M\n",
    "                \n",
    "            elif x < M and (y < fL or y < fM): R = M\n",
    "            \n",
    "            else: return False\n",
    "            \n",
    "        # If the point is not rejcected in the loop, it is acceptable\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Slice Sampling algorithm\n",
    "\n",
    "Putting it all together, we have a complete MCMC algorithm for sampling from $1$-dimensional distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x0, log_prob, method, params, shrinkage):\n",
    "    \n",
    "    f0 = log_prob(x0)\n",
    "    y = np.log(np.exp(f0) * np.random.rand())\n",
    "    \n",
    "    L = None\n",
    "    R = None\n",
    "    \n",
    "    if method == 'step_out':\n",
    "        w, m = params\n",
    "        L, R, _ = step_out_expansion(x0, y, log_prob, w, m)\n",
    "        \n",
    "    elif method == 'double':\n",
    "        w, p = params\n",
    "        L, R, _ = double_expansion(x0, y, log_prob, w, p)\n",
    "        \n",
    "    x = sample_acceptable_set(x0=x0,\n",
    "                              y=y,\n",
    "                              L=L,\n",
    "                              R=R,\n",
    "                              log_prob=log_prob,\n",
    "                              method=method,\n",
    "                              params=params,\n",
    "                              shrinkage=shrinkage)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography} ./references.bib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-random-walks",
   "language": "python",
   "name": "venv-random-walks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
