{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Fourier features\n",
    "\n",
    "One central difficulty with Gaussian Processes (GPs) -- and more generally all kernel methods, such as Support Vector Machines (SVMs) -- is their computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.d-flex {\n",
       "    display: none!important;\n",
       "}\n",
       "\n",
       ".bd-toc nav {\n",
       "    opacity: 1;\n",
       "    max-height: 100vh!important;\n",
       "}\n",
       "\n",
       ".bd-toc .nav .nav {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".prev-next-bottom {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".footer {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".navbar_footer {\n",
       "\tdisplay: none;\n",
       "}\n",
       "\n",
       ".definition {\n",
       "\tbackground-color: rgba(123, 183, 223, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(123, 183, 223, 0.5);\n",
       "}\n",
       "\n",
       ".theorem {\n",
       "\tbackground-color: rgba(240, 213, 75, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(240, 213, 75, 0.5);\n",
       "}\n",
       "\n",
       ".lemma {\n",
       "\tbackground-color: rgba(255, 218, 185, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(255, 218, 185, 0.5);\n",
       "}\n",
       "\n",
       ".observation {\n",
       "\tbackground-color: rgba(178, 234, 188, 0.33);\n",
       "\tborder-radius: 20px;\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "\tborder-style: solid;\n",
       "\tborder-color: rgba(178, 234, 188, 0.5);\n",
       "}\n",
       "\n",
       "details.proof {\n",
       "    border-width: 2px;\n",
       "\tborder-radius: 20px;\n",
       "\tborder-style: solid;\n",
       "\tbackground-color: rgba(128, 128, 128, 0.2);\n",
       "\tborder-color: rgba(128, 128, 128, 0.1);\n",
       "}\n",
       "\n",
       "\n",
       "details.proof div{\n",
       "\tpadding: 20px 20px 10px 20px;\n",
       "}\n",
       "\n",
       "details.proof {\n",
       "\tpadding: 0px 30px 0px 30px;\n",
       "}\n",
       "\n",
       "summary {\n",
       "\tmargin-left: -32px;\n",
       "\tpadding-left: 15px;\n",
       "\tpadding-right: 15px;\n",
       "}\n",
       "\n",
       "summary + * {\n",
       "    margin-top: 10px;\n",
       "}\n",
       "\n",
       ".tag_center-output div img {\n",
       "    display:block;\n",
       "    margin:auto;\n",
       "}\n",
       "\n",
       ".container {\n",
       "\twidth : 103% !important;\n",
       "}\n",
       "\n",
       "details > .math.notranslate.nohighlight {\n",
       "\tmargin-top: -50px;\n",
       "\tmargin-bottom: -15px;\n",
       "}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import HTML, set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "css_style = open('../../../_static/custom_style.css', 'r').read()\n",
    "HTML(f'<style>{css_style}</style>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"theorem\">\n",
    "    \n",
    "**Theorem (Bochner's theorem)** A continuous kernnel $k(x, y) = k(x - y)$ is positive definite if and only if $k(\\delta)$ is the Fourier transform of a non-negative measure.\n",
    "    \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Note that this statement slightly abuses the $k$ symbol, using it to denote both the kernel $k(x, y)$ as well as its writing in an explicitly translation-invariant form $k(x - y)$ -- the implied use is clear from context. Bochner's theorem implies that for any translation-invariant kernel $k$, there exists a corresponding non-negative measure such that $k$ is the Fourier transform of it.\n",
    "\n",
    "$$\\begin{align}\n",
    "k(x - y) = \\int p(\\omega) e^{i \\omega^\\top (x - y)} d\\omega = \\mathbb{E}_{\\omega}\\left[\\zeta_{\\omega}(x)\\zeta_{\\omega}^*(y)\\right].\n",
    "\\end{align}$$\n",
    "\n",
    "We can therefore get an unbiased estimate of $k(x - y)$ by sampling $\\omega \\sim p(\\omega)$ and computing $\\zeta_{\\omega}(x)\\zeta_{\\omega}^*(y)$. Note however, that even though $\\mathbb{E}_{\\omega}\\left[\\zeta_{\\omega}(x)\\zeta_{\\omega}^*(y)\\right]$ is real, the sampled $\\zeta_{\\omega}(x)\\zeta_{\\omega}^*(y)$ will in general be complex. This is an issue if we want to use $\\zeta_{\\omega}$ to represent real functions. Instead, we can write\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{\\omega}\\left[\\zeta_{\\omega}(x)\\zeta_{\\omega}^*(y)\\right] &= \\text{Re}\\left[\\mathbb{E}_{\\omega}\\left[e^{i \\omega^\\top (x - y)}\\right]\\right] \\\\\n",
    "                                                                     &= \\mathbb{E}_{\\omega}\\left[\\text{Re}\\left[e^{i \\omega^\\top (x - y)}\\right]\\right] \\\\\n",
    "                                                                     &= \\mathbb{E}_{\\omega}\\left[\\cos(\\omega^\\top (x - y))\\right].\n",
    "\\end{align}$$\n",
    "\n",
    "We would like to manipulate the expression above into an expectation of the form $\\mathbb{E}_{\\omega}\\left[f(x)f(y)\\right]$ rather than $\\mathbb{E}_{\\omega}\\left[f(x - y)\\right]$, which we can achieve via the following trick. Using the fact that\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{\\phi}\\left[\\cos(z + n\\phi)\\right] = 0,\n",
    "\\end{align}$$\n",
    "\n",
    "for all $z \\in \\mathbb{R}, n \\in \\mathbb{N}^+$, where $\\phi \\sim \\text{Uniform}[0, 2\\pi]$, we can re-write the expectation as\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{\\omega}\\left[\\zeta_{\\omega}(x)\\zeta_{\\omega}^*(y)\\right] &= \\mathbb{E}_{\\omega, \\phi}\\left[\\cos\\left(\\omega^\\top (x - y)\\right) + \\cos\\left(\\omega^\\top (x + y\\right) + 2b)\\right] \\\\\n",
    "                                                                     &= \\mathbb{E}_{\\omega, \\phi}\\left[2 \\cos\\left(\\omega^\\top x + b\\right) \\cos\\left(\\omega^\\top y + b\\right)\\right].\n",
    "\\end{align}$$\n",
    "\n",
    "We can therefore get an unbiased, real valued estimate of $k(x - y)$ by sampling $\\omega \\sim p(\\omega), \\phi \\sim \\text{Uniform}[0, 2\\pi]$ and computing\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{\\omega}\\left[\\zeta_{\\omega}(x)\\zeta_{\\omega}^*(y)\\right] \\approx z_{\\omega, b}(x) z_{\\omega, b}(y), \\text{ where } z_{\\omega, b}(x) = \\sqrt{2} \\cos(\\omega^\\top x + b).\n",
    "\\end{align}$$\n",
    "\n",
    "In fact, we can go a bit further by drawing $N$ independent pairs of $\\omega, b$ and computing the estimate\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{\\omega}\\left[\\zeta_{\\omega}(x)\\zeta_{\\omega}^*(y)\\right] \\approx \\frac{1}{N} \\sum_{n = 1}^N z_{\\omega_n, \\phi_n}(x) z_{\\omega_n, \\phi_n}(y).\n",
    "\\end{align}$$\n",
    "\n",
    "This is also an unbiased estimate of $k$, however its variance is lower than in the $N = 1$ case, since the variance of the average of the sum of $N$ i.i.d. random variables is lower than the variance of a single one of the variables. We therefore arrive at the following algorithm for estimating $k$.\n",
    "\n",
    "<div class=\"definition\">\n",
    "    \n",
    "**Algorithm (Random Fourier Features)** Given a translation invariant kernel $k$ that is the Fourier transform of a probability measure $p$, we have the unbiased real-valued estimator\n",
    "    \n",
    "$$\\begin{align}\n",
    "k(x - y) \\approx \\frac{1}{N} \\sum_{n = 1}^N z_{\\omega_n, \\phi_n}(x) z_{\\omega_n, \\phi_n}(y) = z^\\top(x)z(y),\n",
    "\\end{align}$$\n",
    "    \n",
    "where we have used the notation $z(x) = \\left[ z_{\\omega_1, \\phi_1}(x), ..., z_{\\omega_N, \\phi_N}(x) \\right]^\\top$ and $\\omega_n \\sim p(\\omega), \\phi_n \\sim \\text{Uniform}[0, 2\\pi]$ are independent and identically distributed samples.\n",
    "    \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Now there remains the question of how large the error of this estimator is. Since $-\\sqrt{2} \\leq z_{\\omega, \\phi} \\leq \\sqrt{2}$, we can use Hoeffding's inequality{cite}`grimmett2020probability` to obtain the following high-probability bound on the absolute error.\n",
    "\n",
    "<div class=\"lemma\">\n",
    "    \n",
    "**Result (Hoeffding for RFF)** The RFF estimator of $k$, using $N$ pairs of $\\omega, b$, obeys\n",
    "    \n",
    "$$\\begin{align}\n",
    "p\\big(|z^\\top(x)z(y) - k(x, y)| \\geq \\epsilon \\big) \\leq 2 \\exp\\left(-N \\frac{\\epsilon^2}{4}\\right).\n",
    "\\end{align}$$\n",
    "    \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Therefore for any given input pair, the error of the RFF estimator decays exponentially quickly with $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography} ./references.bib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-random-walks",
   "language": "python",
   "name": "venv-random-walks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
