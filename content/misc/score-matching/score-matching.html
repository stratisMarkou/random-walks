
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Estimation by score matching &#8212; Random walks</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom_style.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/.ipynb_checkpoints/custom_style-checkpoint.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/language_data.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://random-walks.org/content/misc/score-matching/score-matching.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Interacting particle solutions of the FPK" href="../interacting/interacting.html" />
    <link rel="prev" title="Adaptive rejection sampling" href="../ars/ars.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://random-walks.org/content/misc/score-matching/score-matching.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Estimation by score matching" />
<meta property="og:description" content="Estimation by score matching  This page presents a useful trick due to Hyvarinen,[HyvarinenD05] for estimating intractable probabilistic moodels via score-match" />
<meta property="og:image"       content="https://random-walks.org/_static/logo.svg" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/logo.svg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Random walks</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../home.html">
   Welcome
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../prob-intro/intro.html">
   Probability: An introduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch01/content.html">
     Events and Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch02/content.html">
     Discrete random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch03/content.html">
     Multivariate discrete distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch04/content.html">
     Probability generating functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch05/content.html">
     Distribution and density functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch06/content.html">
     Multivariate distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch07/content.html">
     Moment generating functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch08/content.html">
     Main limit theorems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch09/content.html">
     Branching processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch10/content.html">
     Random walks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch11/content.html">
     Processes in continuous time
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../prob-intro/ch12/content.html">
     Markov chains
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../gp/gp-intro.html">
   Gaussian Processes
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../gp/why-covariances.html">
     Why covariance functions?
    </a>
   </li>
   <li class="toctree-l2 collapsible-parent">
    <a class="reference internal" href="../../gp/sparse/sparse-intro.html">
     Sparse Gaussian Processes
    </a>
    <ul class="collapse-ul">
     <li class="toctree-l3">
      <a class="reference internal" href="../../gp/sparse/vfe.html">
       Variational Free Energy GPs
      </a>
     </li>
    </ul>
    <i class="fas fa-chevron-down">
    </i>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="../misc.html">
   Miscellaneous
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../sde/num-sde.html">
     Numerical simulation of SDEs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../sde-as-gp/sde-as-gp.html">
     VI for diffusion processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../node/node.html">
     Neural ODEs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../optimisation/conjugate-gradients.html">
     Conjugate gradients
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../kalman/kalman.html">
     The Kalman filter and smoother
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ncs/ncs.html">
     Natural cubic splines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ars/ars.html">
     Adaptive rejection sampling
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Estimation by score matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../interacting/interacting.html">
     Interacting particle FPK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../rff/rff.html">
     Random Fourier features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../svgd/svgd.html">
     Stein variational gradient descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../addgp/addgp.html">
     Additive Gaussian Processes
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../reading-and-links.html">
   Interesting reading and websites
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/content/misc/score-matching/score-matching.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-score-matching-trick">
   The score matching trick
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="estimation-by-score-matching">
<h1>Estimation by score matching<a class="headerlink" href="#estimation-by-score-matching" title="Permalink to this headline">¶</a></h1>
<p>This page presents a useful trick due to Hyvarinen,<a class="bibtex reference internal" href="#hyvarinen2005estimation" id="id1">[HyvarinenD05]</a> for estimating intractable probabilistic moodels via score-matching. Score matching can be used to train probabilistic models whose likelihood function takes the form</p>
<div class="math notranslate nohighlight">
\[\begin{align}
p(x | \theta) = \frac{1}{Z} q(x; \theta),
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(q(x; \theta)\)</span> is a positive function we can evaluate, but <span class="math notranslate nohighlight">\(Z\)</span> is a normalising constant which we cannot evaluate in closed form. Such models are called non-normalised models. Non-gaussian Markov random fields are examples of such models.</p>
<div class="section" id="the-score-matching-trick">
<h2>The score matching trick<a class="headerlink" href="#the-score-matching-trick" title="Permalink to this headline">¶</a></h2>
<p>The first step for the score-matching trick is to notice that taking the log and then the gradient with respect to <span class="math notranslate nohighlight">\(x\)</span> of both sides eliminates the intractable <span class="math notranslate nohighlight">\(Z\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{align}
\nabla \log p(x; \theta) = \nabla \log q(x; \theta),
\end{align}\]</div>
<p>since <span class="math notranslate nohighlight">\(Z\)</span> does not depend on <span class="math notranslate nohighlight">\(x\)</span>. The gradient of the log-likelihood is called the score function</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\nabla \log p(x; \theta) = \psi(x; \theta).
\end{align}\]</div>
<p>The second step is to find a way to use the score function <span class="math notranslate nohighlight">\(\psi(x; \theta)\)</span> along with some observed data, to estimate the parameters <span class="math notranslate nohighlight">\(\theta\)</span>. We can achieve this by defining the following score matching objective.</p>
<div class="definition">
<p><strong>Definition (Score matching objective)</strong> Given a data distribution <span class="math notranslate nohighlight">\(p_d(x)\)</span> and an approximating distribution <span class="math notranslate nohighlight">\(p(x; \theta)\)</span> with parameters <span class="math notranslate nohighlight">\(\theta\)</span>, we define the score matching objective as</p>
<div class="math notranslate nohighlight">
\[\begin{align}
J(\theta) = \frac{1}{2} \int p_d(x) || \psi(x; \theta) - \psi_d(x)||^2 dx,
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(\psi(x; \theta) = \nabla p(x;, \theta)\)</span> and <span class="math notranslate nohighlight">\(\psi_d(x) = \nabla p_d(x)\)</span> and the derivatives are with respect to <span class="math notranslate nohighlight">\(x\)</span>.</p>
</div>
<br>
<p>We observe that if <span class="math notranslate nohighlight">\(J(\theta) = 0\)</span>, then <span class="math notranslate nohighlight">\(\psi(x; \theta) = \psi_d(x)\)</span> almost always. So we might expect that in this case the model distribution <span class="math notranslate nohighlight">\(p(x; \theta)\)</span> and <span class="math notranslate nohighlight">\(p_d(x)\)</span> will also be equal. This intuition is formalised by the following result.</p>
<div class="theorem">
<p><strong>Theorem (Score matching <span class="math notranslate nohighlight">\(\iff\)</span> maximum likelihood)</strong> Suppose that the probability density function of <span class="math notranslate nohighlight">\(x\)</span> satisfies <span class="math notranslate nohighlight">\(p_d(x) = p(x; \theta)\)</span> for some <span class="math notranslate nohighlight">\(\theta^*\)</span> and also that if <span class="math notranslate nohighlight">\(\theta^* \neq \theta\)</span> then <span class="math notranslate nohighlight">\(p(x; \theta) \neq p_d(x)\)</span>. Suppose also that <span class="math notranslate nohighlight">\(p(x; \theta) &gt; 0\)</span>. Then</p>
<div class="math notranslate nohighlight">
\[\begin{align}
J(\theta) = 0 \iff \theta = \theta^*.
\end{align}\]</div>
</div>
<br>
<details class="proof">
<summary>Proof: Score matching \(\iff\) maximum likelihood</summary>
<p><strong>Is implied by:</strong> We can see that <span class="math notranslate nohighlight">\(\theta = \theta^* \implies J(\theta) = 0\)</span> by substituting <span class="math notranslate nohighlight">\(p_d(x) = p(x; \theta^*)\)</span> into <span class="math notranslate nohighlight">\(J(\theta^*)\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
J(\theta^*) &amp;= \frac{1}{2} \int p_d(x) || \psi(x; \theta^*) - \psi_d(x)||^2 dx \\
            &amp;= \frac{1}{2} \int p(x; \theta^*) || \psi(x; \theta^*) - \psi(x; \theta^*)||^2 dx \\
            &amp;= 0.
\end{align}\end{split}\]</div>
<p><strong>Implies:</strong> Going the other direction, we can show that <span class="math notranslate nohighlight">\(J(\theta) = 0 \implies \theta = \theta^*\)</span> by considering</p>
<div class="math notranslate nohighlight">
\[\begin{align}
J(\theta) &amp;= \frac{1}{2} \int p(x; \theta^*) || \psi(x; \theta) - \psi(x; \theta^*)||^2 dx = 0.
\end{align}\]</div>
<p>Since <span class="math notranslate nohighlight">\(p(x; \theta^*) &gt; 0\)</span>, the above can hold only if <span class="math notranslate nohighlight">\(\psi(x; \theta) = \psi(x; \theta^*)\)</span> for every <span class="math notranslate nohighlight">\(x\)</span>. This means that</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\psi(x; \theta) = \psi(x; \theta^*) + \text{const.} \implies p(x; \theta) \propto p(x; \theta^*),
\end{align}\]</div>
<p>and since <span class="math notranslate nohighlight">\(p(x; \theta^*)\)</span> is a normalised probability distribution, we arrive at <span class="math notranslate nohighlight">\(p(x; \theta) = p(x; \theta^*)\)</span>. Now since the <span class="math notranslate nohighlight">\(p(x; \theta^*)\)</span> is unique for the particular <span class="math notranslate nohighlight">\(\theta^*\)</span>, we have that <span class="math notranslate nohighlight">\(\theta = \theta^*\)</span>.</p>
</details>
<br>
<p>This result confirms the intuition that if the score functions (of the data distribution and the model) are equal, then the distributions equal as well. However, we note that this theorem assumes that <span class="math notranslate nohighlight">\(p_d(x) = p(x; \theta)\)</span> for some <span class="math notranslate nohighlight">\(\theta\)</span>. In other words, it is assumed that the true model <span class="math notranslate nohighlight">\(p_d(x)\)</span> is within the space of models we have hypothesised. In general this will not be true for true data, but at least the present result confirms that the expected behaviour is recovered in this idealised setting.</p>
<p>The last challenge is that in its definition <span class="math notranslate nohighlight">\(J(\theta)\)</span> depends explicitly on <span class="math notranslate nohighlight">\(\psi_d(x)\)</span>, a function we do not have access to. In particular, expanding the term in the norm, we see that</p>
<div class="math notranslate nohighlight">
\[\begin{align}
|| \psi(x; \theta) - \psi(x; \theta^*)||^2 = ||\psi(x; \theta)^\top\psi(x; \theta) - 2\psi(x; \theta)^\top\psi_d(x) + \psi_d(x)^\top\psi_d(x)||.
\end{align}\]</div>
<p>The first term is computable because we have access to <span class="math notranslate nohighlight">\(\psi(x; \theta)\)</span>. The latter term does not depend on <span class="math notranslate nohighlight">\(\theta\)</span> and is therefore irrelevant for the optimisation of <span class="math notranslate nohighlight">\(J(\theta)\)</span>. However the middle term both depends on <span class="math notranslate nohighlight">\(\theta\)</span> as well as the inaccessible score function of the data <span class="math notranslate nohighlight">\(\psi_d(x)\)</span>. Therefore this term must be considered in the optimisation of <span class="math notranslate nohighlight">\(J(\theta)\)</span> but is also not directly computable. By using integration by parts, one can show<a class="bibtex reference internal" href="#hyvarinen2005estimation" id="id2">[HyvarinenD05]</a> that this term can be rewritten in a way such that <span class="math notranslate nohighlight">\(J(\theta)\)</span> can be estimated empirically.</p>
<div class="theorem">
<p><strong>Theorem (Equivalent form of <span class="math notranslate nohighlight">\(J\)</span>)</strong> Given a score function <span class="math notranslate nohighlight">\(\psi(x; \theta)\)</span> which is differentiable w.r.t. <span class="math notranslate nohighlight">\(x\)</span> and satisfies some weak regularity conditions. Then the score-matching function <span class="math notranslate nohighlight">\(J\)</span> can be writtten as</p>
<div class="math notranslate nohighlight">
\[\begin{align}
J(\theta) = \int p_d(x) \sum^N_{i = 1}\left[ \partial_i \psi_i(x; \theta) + \frac{1}{2} \psi_{d, i}(x; \theta)^2 \right] dx + \text{const.},
\end{align}\]</div>
<p>where the <span class="math notranslate nohighlight">\(i\)</span>-subscript denotes the <span class="math notranslate nohighlight">\(i^{th}\)</span> entry of vector being indexed and <span class="math notranslate nohighlight">\(\partial_i\)</span> denotes the partial derivative with respect to <span class="math notranslate nohighlight">\(x_i\)</span>. The constant term is independent of <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</div>
<br>
<details class="proof">
<summary>Proof: Equivalent form of \(J\)</summary>
<p>Writing out <span class="math notranslate nohighlight">\(J\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{align}
J(\theta) = \frac{1}{2} \int p_d(x) \left[ \psi(x; \theta)^\top\psi(x; \theta) - 2\psi(x; \theta)^\top\psi_d(x) + \psi_d(x)^\top\psi_d(x)\right] dx,
\end{align}\]</div>
<p>we see that the last term in the brackets evaluates to a constant that is independent of <span class="math notranslate nohighlight">\(\theta\)</span>. Using the fact that</p>
<div class="math notranslate nohighlight">
\[\begin{align}
p_d(x) \psi_d(x) = p_d(x) \nabla \log p_d(x) = \nabla p_d(x),
\end{align}\]</div>
<p>and applying integration by parts, we obtain</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\int p_d(x) \psi(x; \theta)^\top\psi_d(x) dx &amp;= \int \psi(x; \theta)^\top \nabla p_d(x) dx \\
&amp;= \big[p_d(x) \psi(x; \theta) \big]_{-\infty}^{\infty} - \int p_d(x) \partial_i \psi_{d, i}(x; \theta) dx.
\end{align}\end{split}\]</div>
<p>Substituting this into the expression for <span class="math notranslate nohighlight">\(J\)</span> we arrive at</p>
<div class="math notranslate nohighlight">
\[\begin{align}
J(\theta) = \int p_d(x) \sum^N_{i = 1}\left[ \partial_i \psi_i(x; \theta) + \frac{1}{2} \psi_{d, i}(x; \theta)^2 \right] dx + \text{const.}
\end{align}\]</div>
</details>
<br>
<p>The proof has used integration by parts to replace the intractable <span class="math notranslate nohighlight">\(\psi_d(x)\)</span> term by a <span class="math notranslate nohighlight">\(p_d(x)\)</span> term. This expression can be easily estimated if samples of <span class="math notranslate nohighlight">\(x\)</span> are available, by replacing the expectation with respect to <span class="math notranslate nohighlight">\(p_d(x)\)</span> by the empirical average over the samples. In this way, we can estimate the parameters <span class="math notranslate nohighlight">\(\theta\)</span> of a non-normalised model, without resorting to computing estimates of the density <span class="math notranslate nohighlight">\(p_d(x)\)</span>.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-content/misc/score-matching/score-matching-0"><dl class="citation">
<dt class="bibtex label" id="hyvarinen2005estimation"><span class="brackets">HyvarinenD05</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>)</span></dt>
<dd><p>Aapo Hyvärinen and Peter Dayan. Estimation of non-normalized statistical models by score matching. <em>Journal of Machine Learning Research</em>, 2005.</p>
</dd>
</dl>
</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/misc/score-matching"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../ars/ars.html" title="previous page">Adaptive rejection sampling</a>
    <a class='right-next' id="next-link" href="../interacting/interacting.html" title="next page">Interacting particle solutions of the FPK</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Stratos Markou<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-168728006-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>