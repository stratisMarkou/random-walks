{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from check_shape import check_shape\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EQcovariance(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, \n",
    "                 log_coeff,\n",
    "                 log_scales,\n",
    "                 dtype,\n",
    "                 trainable=True,\n",
    "                 name='eq_covariance',\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__(name=name, dtype=dtype, **kwargs)\n",
    "    \n",
    "        # Convert parameters to tensors\n",
    "        log_coeff = tf.convert_to_tensor(log_coeff, dtype=dtype)\n",
    "        log_scales = tf.convert_to_tensor(log_scales, dtype=dtype)\n",
    "\n",
    "        # Reshape parameter tensors\n",
    "        log_coeff = tf.squeeze(log_coeff)\n",
    "        log_scales = tf.reshape(log_scales, (-1,))\n",
    "        \n",
    "        # Set EQ parameters\n",
    "        self.log_scales = tf.Variable(log_scales, trainable=trainable)\n",
    "        self.log_coeff = tf.Variable(log_coeff, trainable=trainable)\n",
    "        \n",
    "    def call(self,\n",
    "             x1,\n",
    "             x2,\n",
    "             diag=False,\n",
    "             epsilon=None):\n",
    "        \n",
    "        # Convert to tensors\n",
    "        x1 = tf.convert_to_tensor(x1, dtype=self.dtype)\n",
    "        x2 = tf.convert_to_tensor(x2, dtype=self.dtype)\n",
    "\n",
    "        # Get vector of lengthscales\n",
    "        scales = self.scales\n",
    "        \n",
    "        # If calculating full covariance, add dimensions to broadcast\n",
    "        if not diag:\n",
    "\n",
    "            x1 = x1[:, None, :]\n",
    "            x2 = x2[None, :, :]\n",
    "\n",
    "            scales = self.scales[None, None, :] ** 2\n",
    "\n",
    "        # Compute quadratic, exponentiate and multiply by coefficient\n",
    "        quad = - 0.5 * (x1 - x2) ** 2 / scales\n",
    "        quad = tf.reduce_sum(quad, axis=-1)\n",
    "        eq_cov = self.coeff ** 2 * tf.exp(quad)\n",
    "        \n",
    "        # Add jitter for invertibility\n",
    "        if epsilon is not None:\n",
    "            eq_cov = eq_cov + epsilon * tf.eye(\n",
    "                eq_cov.shape[0], \n",
    "                dtype=self.dtype\n",
    "            )\n",
    "\n",
    "        return eq_cov\n",
    "        \n",
    "    @property\n",
    "    def scales(self):\n",
    "        return tf.math.exp(self.log_scales)\n",
    "    \n",
    "    @property\n",
    "    def coeff(self):\n",
    "        return tf.math.exp(self.log_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_coeff = [0.]\n",
    "log_scales = [0.]\n",
    "dtype = tf.float64\n",
    "trainable = True\n",
    "\n",
    "covariance = EQcovariance(\n",
    "    log_coeff=log_coeff,\n",
    "    log_scales=log_scales,\n",
    "    dtype=dtype,\n",
    "    trainable=trainable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, log_noise, trainable_noise, covariance, dtype, name=\"gp\", **kwargs):\n",
    "        \n",
    "        super().__init__(name=name, dtype=dtype, **kwargs)\n",
    "        \n",
    "        self.log_noise = tf.convert_to_tensor(log_noise)\n",
    "        self.log_noise = tf.Variable(log_noise, trainable=trainable_noise, dtype=dtype)\n",
    "        \n",
    "        self.covariance = covariance\n",
    "    \n",
    "    def posterior_predictive(self, x_train, y_train, x_pred):\n",
    "        \n",
    "        N = x_train.shape[0]\n",
    "        Neye = tf.eye(N, dtype=self.dtype)\n",
    "        \n",
    "        M = x_test.shape[0]\n",
    "        Meye = tf.eye(M, dtype=self.dtype)\n",
    "        \n",
    "        Ktt = self.covariance(x_train, x_train)\n",
    "        Ktp = self.covariance(x_train, x_pred)\n",
    "        Kpt = self.covariance(x_pred, x_train)\n",
    "        Kpp = self.covariance(x_pred, x_pred)\n",
    "        \n",
    "        mean = Kpt @ tf.linalg.solve(Ktt + Neye * self.noise**2., y_train[:, None])\n",
    "        mean = mean[:, 0]\n",
    "        \n",
    "        cov = Kpp - Kpt @ tf.linalg.solve(Ktt + Neye * self.noise**2., Ktp) + Meye * self.noise**2.\n",
    "        var = tf.linalg.diag_part(cov)\n",
    "        \n",
    "        return mean, cov, var\n",
    "    \n",
    "    def marg_lik_loss(self, x, y):\n",
    "        \n",
    "        N = x.shape[0]\n",
    "        eye = tf.eye(N, dtype=self.dtype)\n",
    "        \n",
    "        loc = tf.zeros_like(y)\n",
    "        cov = self.covariance(x, x)\n",
    "        cov = cov + eye * self.noise**2\n",
    "        \n",
    "        normal = tfp.distributions.MultivariateNormalFullCovariance(\n",
    "            loc=loc,\n",
    "            covariance_matrix=cov\n",
    "        )\n",
    "        \n",
    "        marg_lik = normal.log_prob(y)\n",
    "        loss = - marg_lik / N\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    @tf.function\n",
    "    def loo_loss(self, x, y):\n",
    "        \n",
    "        N = x.shape[0]\n",
    "        \n",
    "        # Compute stable inverse once\n",
    "        cov, prec = self.full_covariance_and_precision(x)\n",
    "        \n",
    "        logpdf = tf.convert_to_tensor(0., dtype=self.dtype)\n",
    "        \n",
    "        for n in tf.range(N):\n",
    "            \n",
    "            loo_prec, D, B, C = self.loo_precision_and_covariance_submatrices(\n",
    "                cov=cov,\n",
    "                prec=prec,\n",
    "                n=n\n",
    "            )\n",
    "            \n",
    "            y_roll = tf.roll(y, shift=n, axis=0)\n",
    "            y_cond = y_roll[:-1, None]\n",
    "            y_pred = y_roll[-1:, None]\n",
    "            \n",
    "            loc = C @ loo_prec @ y_cond\n",
    "            scale = (D - C @ loo_prec @ B) ** 0.5\n",
    "\n",
    "            normal = tfp.distributions.Normal(loc=loc, scale=scale)\n",
    "            logpdf = logpdf + normal.log_prob(y_pred)[0, 0]\n",
    "            \n",
    "        loss = - logpdf / N\n",
    "            \n",
    "        return loss\n",
    "        \n",
    "    def full_covariance_and_precision(self, x):\n",
    "        \n",
    "        N = x.shape[0]\n",
    "        eye = tf.eye(N, dtype=self.dtype)\n",
    "        \n",
    "        cov = self.covariance(x, x)\n",
    "        cov = cov + eye * self.noise**2\n",
    "        \n",
    "        chol_cov = tf.linalg.cholesky(cov)\n",
    "        chol_prec = tf.linalg.triangular_solve(chol_cov, eye, lower=True)\n",
    "        \n",
    "        prec = tf.matmul(chol_prec, chol_prec, transpose_a=True)\n",
    "        \n",
    "        return cov, prec\n",
    "    \n",
    "    @tf.function\n",
    "    def loo_precision_and_covariance_submatrices(self, cov, prec, n):\n",
    "        \n",
    "        permute = lambda mat: tf.roll(tf.roll(mat, shift=n, axis=0), shift=n, axis=1)\n",
    "        \n",
    "        # Permute covariance and precision so the leave-out point is bottom right\n",
    "        cov = permute(cov)\n",
    "        prec = permute(prec)\n",
    "         \n",
    "        B = cov[:-1, -1:]\n",
    "        C = cov[-1:, :-1]\n",
    "        D = cov[-1:, -1:]\n",
    "        G = prec[-1:, :-1]\n",
    "        E = prec[:-1, :-1]\n",
    "        \n",
    "        loo_prec = E + tf.matmul(tf.matmul(E, B), G) / tf.reshape((1. - tf.matmul(G, B)), (-1,))\n",
    "        \n",
    "        return loo_prec, D, B, C\n",
    "        \n",
    "    @property\n",
    "    def noise(self):\n",
    "        return tf.exp(self.log_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_coeff = [0.]\n",
    "log_scales = [-2.]\n",
    "dtype = tf.float64\n",
    "trainable = True\n",
    "log_noise = -8.\n",
    "trainable_noise = True\n",
    "\n",
    "covariance = EQcovariance(\n",
    "    log_coeff=log_coeff,\n",
    "    log_scales=log_scales,\n",
    "    dtype=dtype,\n",
    "    trainable=trainable\n",
    ")\n",
    "\n",
    "gp = GP(\n",
    "    log_noise=log_noise,\n",
    "    trainable_noise=trainable_noise,\n",
    "    covariance=covariance,\n",
    "    dtype=dtype\n",
    ")\n",
    "\n",
    "x = tf.random.uniform(shape=(100, 1), dtype=dtype)\n",
    "cov, prec = gp.full_covariance_and_precision(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.868662073167221e-05, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform(shape=(300, 1), dtype=dtype)\n",
    "cov, prec = gp.full_covariance_and_precision(x)\n",
    "n = 100\n",
    "\n",
    "permute = lambda mat, n: tf.roll(tf.roll(mat, shift=n, axis=0), shift=n, axis=1)\n",
    "\n",
    "print(tf.reduce_sum((gp.loo_precision_and_covariance_submatrices(cov, prec, n)[0] \\\n",
    "                     - tf.linalg.inv(permute(cov, n)[:-1, :-1]))**2)/300**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:334: MultivariateNormalFullCovariance.__init__ (from tensorflow_probability.python.distributions.mvn_full_covariance) is deprecated and will be removed after 2019-12-01.\n",
      "Instructions for updating:\n",
      "`MultivariateNormalFullCovariance` is deprecated, use `MultivariateNormalTriL(loc=loc, scale_tril=tf.linalg.cholesky(covariance_matrix))` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-6.661863632667553>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.marg_lik_loss(x, x[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load pre-downloaded concrete dataset\n",
    "# x = np.load('data/concrete/x.npy')\n",
    "# y = np.load('data/concrete/y.npy')\n",
    "\n",
    "# # Normalise inputs and outputs\n",
    "# x = (x - x.mean(axis=0)) / x.var(axis=0) ** 0.5\n",
    "# y = (y - y.mean()) / y.var() ** 0.5\n",
    "\n",
    "# num_train = 500\n",
    "\n",
    "# # Split into training and test sets\n",
    "# x_train = x[:num_train]\n",
    "# y_train = y[:num_train, 0]\n",
    "# x_test = x[num_train:]\n",
    "# y_test = y[num_train:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(num_dim, gamma, noise, num_train, num_test, dtype):\n",
    "    \n",
    "    num_total = num_train + num_test\n",
    "    \n",
    "    x = 10. * tf.random.uniform(shape=(num_total, num_dim)) - 5.\n",
    "    \n",
    "    y = gamma * tf.reduce_sum(tf.nn.softplus(x), axis=1, keepdims=True)\n",
    "    y = y + noise * tf.random.normal(shape=y.shape)\n",
    "    \n",
    "    x_train = tf.cast(x[:num_train], dtype=dtype)\n",
    "    y_train = tf.cast(y[:num_train, 0], dtype=dtype)\n",
    "    x_test = tf.cast(x[num_train:], dtype=dtype)\n",
    "    y_test = tf.cast(y[num_train:, 0], dtype=dtype)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def single_step(model, optimiser, x_train, y_train, x_test, y_test):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = model.loo_loss(x_train, y_train)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimiser.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    mean, cov, var = gp.posterior_predictive(x_train, y_train, x_test)\n",
    "    rmse = tf.reduce_mean((mean - y_test)**2)**0.5\n",
    "    normal = tfp.distributions.MultivariateNormalFullCovariance(\n",
    "        loc=mean,\n",
    "        covariance_matrix=cov,\n",
    "    )\n",
    "    log_lik = normal.log_prob(y_test) / y_test.shape[0]\n",
    "\n",
    "    return loss, rmse, log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "num_dim = 4\n",
    "gamma = 2\n",
    "noise = 1e-1\n",
    "num_train = 500\n",
    "num_test = 1000\n",
    "\n",
    "x_train, y_train, x_test, y_test = generate_dataset(\n",
    "    num_dim=num_dim,\n",
    "    gamma=gamma,\n",
    "    noise=noise,\n",
    "    num_train=num_train,\n",
    "    num_test=num_test,\n",
    "    dtype=dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd849152db9e424494892acac54b63ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0a7c7e7a9a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_steps = 5000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "log_coeff = [0.]\n",
    "log_scales = x_train.shape[1] * [0.]\n",
    "dtype = tf.float64\n",
    "trainable = True\n",
    "log_noise = 0.\n",
    "trainable_noise = True\n",
    "\n",
    "covariance = EQcovariance(\n",
    "    log_coeff=log_coeff,\n",
    "    log_scales=log_scales,\n",
    "    dtype=dtype,\n",
    "    trainable=trainable\n",
    ")\n",
    "\n",
    "gp = GP(\n",
    "    log_noise=log_noise,\n",
    "    trainable_noise=trainable_noise,\n",
    "    covariance=covariance,\n",
    "    dtype=dtype\n",
    ")\n",
    "\n",
    "# Initialise optimiser\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "# Set progress bar and suppress warnings\n",
    "progress_bar = tqdm(range(1, num_steps+1), bar_format=\"{l_bar}{r_bar}\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Train model\n",
    "for i in progress_bar:\n",
    "        \n",
    "    loss, rmse, log_lik = single_step(\n",
    "        model=gp,\n",
    "        optimiser=optimiser,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test\n",
    "    )\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        \n",
    "        progress_bar.set_description(\n",
    "            f\"Loss {loss.numpy():.3f} \"\n",
    "            f\"Test RMSE {rmse.numpy():.3f} \"\n",
    "            f\"Test LL {log_lik.numpy():.3f} \"\n",
    "            f\"Noise {gp.noise.numpy():.2f} \"\n",
    "            f\"Coeff {gp.covariance.coeff.numpy():.2f} \"\n",
    "            f\"Scale {gp.covariance.scales.numpy()[0]:.2f} \"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntetic (gamma = 2)\n",
    "# Marglik : Loss 0.856 Test RMSE 0.350 Test LL -0.044 Noise 0.23 Coeff 19.02 Scale 14.93\n",
    "# LOO     : Loss 0.041 Test RMSE 0.251 Test LL  0.536 Noise 0.09 Coeff 12.46 Scale 7.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-rank approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(0)\n",
    "\n",
    "# x = tf.convert_to_tensor(np.random.rand(3))[:, None]\n",
    "# u = tf.convert_to_tensor(np.random.rand(2))[:, None]\n",
    "# sigma = 1e-1\n",
    "\n",
    "# log_coeff = [0.]\n",
    "# log_scales = [0.]\n",
    "# dtype = tf.float64\n",
    "# trainable = False\n",
    "\n",
    "# covariance = EQcovariance(\n",
    "#     log_coeff=log_coeff,\n",
    "#     log_scales=log_scales,\n",
    "#     dtype=dtype,\n",
    "#     trainable=trainable\n",
    "# )\n",
    "\n",
    "# A = covariance(u, u)\n",
    "# v1 = covariance(u, x[:1])\n",
    "# v2 = covariance(u, x[-1:])\n",
    "\n",
    "# v1T = covariance(x[:1], u)\n",
    "# v2T = covariance(x[-1:], u)\n",
    "\n",
    "# L1 = tf.linalg.cholesky(Kuu + tf.matmul(v1, v1, transpose_b=True))\n",
    "# L2 = tf.linalg.cholesky(Kuu + tf.matmul(v1, v1, transpose_b=True) + tf.matmul(v2, v2, transpose_b=True))\n",
    "# L2 = tfp.math.cholesky_update(L2, v2[:, 0], multiplier=-1.0)\n",
    "\n",
    "# print(L1)\n",
    "# print(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTCGP(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, inducing_inputs, log_noise, trainable_noise, covariance, dtype, name=\"gp\", **kwargs):\n",
    "        \n",
    "        super().__init__(name=name, dtype=dtype, **kwargs)\n",
    "        \n",
    "        self.inducing_inputs = inducing_inputs\n",
    "        self.log_noise = tf.convert_to_tensor(log_noise)\n",
    "        self.log_noise = tf.Variable(log_noise, trainable=trainable_noise, dtype=dtype)\n",
    "        \n",
    "        self.covariance = covariance\n",
    "    \n",
    "    def posterior_predictive(self, x_train, y_train, x_pred):\n",
    "        pass\n",
    "    \n",
    "    def dtc_marg_lik_loss(self, x, y):\n",
    "        pass\n",
    "        \n",
    "    def dtc_loo_loss(self, x, y, batch_size):\n",
    "        \n",
    "        # Check shapes of input and output tensors\n",
    "        check_shape([x, y], [(\"N\", \"D\"), (\"N\",)])\n",
    "        \n",
    "        N = x.shape[0]\n",
    "        M = self.inducing_inputs.shape[0]\n",
    "        \n",
    "        # Compute matrix terms\n",
    "        Kuu = self.covariance(self.inducing_inputs, self.inducing_inputs)\n",
    "        Kux = self.covariance(self.inducing_inputs, x)\n",
    "        \n",
    "        # Compute cholesky of Nystrom matrix - updated in every step\n",
    "        chol = tf.linalg.cholesky(Kuu + self.noise**-2 * tf.matmul(Kux, Kux, transpose_b=True))\n",
    "        \n",
    "        idx = tf.range(N)\n",
    "        idx_batch = tf.convert_to_tensor(np.random.choice(np.arange(N), size=(batch_size,)), dtype=tf.int32)\n",
    "        \n",
    "#         idx_batch = tf.random.categorical(tf.zeros(shape=(1, N)), num_samples=batch_size)[0, :]\n",
    "#         idx_batch = tf.cast(idx_batch, dtype=tf.int32)\n",
    "        \n",
    "        logpdf = tf.convert_to_tensor(0., dtype=self.dtype)\n",
    "        \n",
    "        for n in idx_batch:\n",
    "            \n",
    "            l_idx = idx == n\n",
    "            r_idx = idx != n\n",
    "\n",
    "            l = tf.boolean_mask(x, l_idx, axis=0)\n",
    "            r = tf.boolean_mask(x, r_idx, axis=0)\n",
    "            \n",
    "            yl = tf.boolean_mask(y, l_idx)\n",
    "            yr = tf.boolean_mask(y, r_idx)\n",
    "            \n",
    "            # Compute covariance submatrices associated with current LOO point\n",
    "            Kll = self.covariance(l, l)\n",
    "            Klr = self.covariance(l, r)\n",
    "            Kru = self.covariance(r, self.inducing_inputs)\n",
    "            Kul = self.covariance(self.inducing_inputs, l)\n",
    "            \n",
    "            # Compute cholesky\n",
    "            L = tfp.math.cholesky_update(chol, Kux[:, n]/self.noise, multiplier=-1.0)\n",
    "            \n",
    "            # Compute mean\n",
    "            mean = tf.linalg.matvec(Kru, yr, transpose_a=True)\n",
    "            mean = tf.linalg.cholesky_solve(L, mean[:, None])[:, 0]\n",
    "            mean = tf.linalg.matvec(Kru, mean)\n",
    "            mean = tf.linalg.matvec(Klr, mean)\n",
    "            mean = self.noise**-2 * tf.linalg.matvec(Klr, yr) - self.noise**-4 * mean\n",
    "            \n",
    "            # Compute variance\n",
    "            var = tf.linalg.matmul(Kru, Klr, transpose_a=True, transpose_b=True)\n",
    "            var = tf.linalg.cholesky_solve(L, var)\n",
    "            var = tf.linalg.matmul(Kru, var)\n",
    "            var = tf.linalg.matmul(Klr, var)\n",
    "            var = self.noise**-2 * tf.matmul(Klr, Klr, transpose_b=True) - self.noise**-4 * var\n",
    "            var = Kll - var + self.noise**2\n",
    "            \n",
    "            # Compute log-probability contribution\n",
    "            normal = tfp.distributions.Normal(loc=mean, scale=var[0]**0.5)\n",
    "            logpdf = logpdf + normal.log_prob(yl)[0]\n",
    "#             print(f\"{yl.numpy()[0]: 8.3f}, {mean.numpy()[0]: 8.3f}, {var.numpy()[0, 0]**0.5: 8.3f}\")\n",
    "            \n",
    "        loss = - logpdf / batch_size\n",
    "            \n",
    "        return loss\n",
    "        \n",
    "    @property\n",
    "    def noise(self):\n",
    "        return tf.exp(self.log_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "num_dim = 4\n",
    "gamma = 2\n",
    "noise = 1e-1\n",
    "num_train = 500\n",
    "num_test = 1000\n",
    "\n",
    "x_train, y_train, x_test, y_test = generate_dataset(\n",
    "    num_dim=num_dim,\n",
    "    gamma=gamma,\n",
    "    noise=noise,\n",
    "    num_train=num_train,\n",
    "    num_test=num_test,\n",
    "    dtype=dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e396cbca4f3246ca916724b8167b4e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-30-4ec88f2516c5>\", line 56, in <module>\n",
      "    batch_size=batch_size\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 807, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n",
      "    cancellation_manager=cancellation_manager)\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 550, in call\n",
      "    ctx=ctx)\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/stratis/repos/random-walks/venv-random-walks/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def single_step(model, optimiser, x_train, y_train, x_test, y_test, batch_size):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = model.dtc_loo_loss(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimiser.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "num_steps = 5000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "log_coeff = [1.]\n",
    "log_scales = x_train.shape[1] * [2.]\n",
    "dtype = tf.float64\n",
    "trainable_covariance = True\n",
    "log_noise = -1.\n",
    "trainable_noise = True\n",
    "batch_size = 5\n",
    "\n",
    "covariance = EQcovariance(\n",
    "    log_coeff=log_coeff,\n",
    "    log_scales=log_scales,\n",
    "    dtype=dtype,\n",
    "    trainable=trainable_covariance\n",
    ")\n",
    "\n",
    "gp = DTCGP(\n",
    "    inducing_inputs=x_train[:100, :],\n",
    "    log_noise=log_noise,\n",
    "    trainable_noise=trainable_noise,\n",
    "    covariance=covariance,\n",
    "    dtype=dtype\n",
    ")\n",
    "\n",
    "# Initialise optimiser\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "# Set progress bar and suppress warnings\n",
    "progress_bar = tqdm(range(1, num_steps+1), bar_format=\"{l_bar}{r_bar}\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Train model\n",
    "for i in progress_bar:\n",
    "        \n",
    "    loss = single_step(\n",
    "        model=gp,\n",
    "        optimiser=optimiser,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    if i % 1 == 0:\n",
    "        \n",
    "        progress_bar.set_description(\n",
    "            f\"Loss {loss.numpy():.3f} \"\n",
    "            f\"Noise {gp.noise.numpy():.2f} \"\n",
    "            f\"Coeff {gp.covariance.coeff.numpy():.2f} \"\n",
    "            f\"Scale {gp.covariance.scales.numpy()[0]:.2f} \"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-random-walks",
   "language": "python",
   "name": "venv-random-walks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
