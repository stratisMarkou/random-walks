---
interact_link: content/convex-optimisation/lecture-3.ipynb
kernel_name: venv-random-walks
kernel_path: content/convex-optimisation
has_widgets: false
title: |-
  Convex functions
pagenum: 8
prev_page:
  url: /convex-optimisation/lecture-2.html
next_page:
  url: /convex-optimisation/lecture-4.html
suffix: .ipynb
search: x f convex mathbb r n function y textbf g dom functions big theta alpha h text log b concave leq any partial domain sum line tilde nabla examples set p top t convexity det order frac composition also inequality affine e geq value max example differentiable definition above ax left right restriction tv positive align lambdai extended condition sublevel strictly still powers ij only tx v mathbf s non definite exists extension second sets jensens sup except xp norm m j lambda where maximum eigenvalue matrix take along restricted begin vx end larger differentiability informal its open follows twice

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Convex functions</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Definition-and-examples">Definition and examples<a class="anchor-link" href="#Definition-and-examples"> </a></h2><p><strong>Convex function:</strong> A function whose domain is convex, and which also satisfies</p>
$$f\big(\theta x + (1 - \theta) y\big) \leq \theta f(x) + (1 - \theta) f(y),$$<p>for every $x, y \in \textbf{dom}(f)$ and $\theta \in [0, 1]$.</p>
<p><strong>Strictly convex function:</strong> As above, except the inequality is strict</p>
$$f\big(\theta x + (1 - \theta) y\big) &lt; \theta f(x) + (1 - \theta) f(y).$$<p><strong>Concave and strictly concave funtions:</strong> Same as the definitions above except the inequality sign goes the other way - the domain still needs to be a convex set. The negative of a concave function is convex and vice versa.</p>
<p><strong>Examples of convex functions in $\mathbb{R}$:</strong></p>
<ul>
<li>affine: $ax + b$, for any $a, b \in \mathbb{R}$.</li>
<li>exponential: $e^{\alpha x}$ for any $\alpha \in \mathbb{R}$.</li>
<li>powers: $x^\alpha$ on $\mathbb{R}_{++}$ for $\alpha \geq 1$ or $\alpha \leq 0$.</li>
<li>powers of absolute value: $|x|^p$ for $p \geq 1$.</li>
</ul>
<p><strong>Examples of concave functions in $\mathbb{R}$:</strong></p>
<ul>
<li>affine: $ax + b$, for any $a, b \in \mathbb{R}$.</li>
<li>logarithm: $\log x$ for $x \in \mathbb{R}_{++}$.</li>
<li>powers: $x^\alpha$ on $\mathbb{R}_{++}$ for $0 \leq \alpha \leq 1$.</li>
</ul>
<p><strong>Examples of convex functions in $\mathbb{R}^n$:</strong></p>
<ul>
<li>affine: $a^\top x + b$, for any $a \in \mathbb{R}^n, b \in \mathbb{R}$.</li>
<li>$p$-norm: $||x||_p = \left[ \sum_{i = 1}^n |x_i|^p\right]^{1/p}$ for $p \geq 0$.</li>
</ul>
<p><strong>Examples of convex functions in $\mathbb{R}^{n \times m}$:</strong></p>
<ul>
<li>affine: $\text{Tr}(A^\top X) = \left[\sum_{i = 1}^n \sum_{j = 1}^m A_{ij} X_{ij}\right] + b$</li>
<li>spectral norm: $f(X) = ||X||_2 = \sigma_{\text{max}}(X) = \lambda^{1/2}_{\text{max}}(X^\top X)$, where $\lambda_{\text{max}}(\cdot)$ is the maximum eigenvalue of a matrix.</li>
</ul>
<h2 id="Restriction-to-a-line">Restriction to a line<a class="anchor-link" href="#Restriction-to-a-line"> </a></h2><p><strong>Restriction to a line:</strong> A function $f$ from $\mathbb{R}^n$ to $\mathbb{R}$ is convex if and only if the restriction $g$ of $f$ on any line, is also convex</p>
$$g(t) = f(x + tv),~~~\textbf{dom}~g = \{t~|~x + tv \in \textbf{dom}~f\},$$<p>for any $x \in \textbf{dom}~f, v \in \mathbb{R}^n$.</p>
<p><strong>Example use of restriction:</strong> Using the above result we can prove the convexity of quite complicated functions. Take for example the function $\log \det : \mathbf{S}_{++}^n \to \mathbb{R}$ and restrict it to a line along matrix $V$. For $\textbf{dom}~g = \{t~|~X + tV \in \textbf{dom}~f\}$ to be non-empty, $V$ will have to be symmetric but does not have to be positive-definite. The restricted function $g$ is</p>
\begin{align}
g(t) = \log \det (X + tV) &amp;= \log \det X + \log \det (I + tX^{-1/2}VX^{-1/2})\\
&amp;= \log \det X + \sum_{i = 1}^n  \log (1 + t \lambda_i)
\end{align}<p>where $\lambda_i$ is the $i^\text{th}$ eigenvalue of $X^{-1/2}VX^{-1/2}$ and $X^{-1/2}$ exists because $X$ is positive-definite. The components $\log (1 + t \lambda_i)$ are all concave regardless of the value of $\lambda_i$, so $g$ is concave along any line in $\mathbf{S}_{++}^n$ and thus $\log \det$ is also concave.</p>
<h2 id="Extended-value-extension">Extended value extension<a class="anchor-link" href="#Extended-value-extension"> </a></h2><p><strong>Extended-value extension:</strong> The extended-value extension $\tilde{f}$ of $f$ is</p>
$$ \tilde{f}(x) = f(x) \text{ if } x\in \textbf{dom}~f, \text{ otherwise } \infty.$$<p>This definition helps to extend the domain of convex functions to a larger set, for example extending $f(x) = x^2, \textbf{dom}~f = \mathbb{R}_{+}$ from the positive reals $\mathbb{R}_{+}$ to the whole real line $\mathbb{R}$ and still have $\tilde{f}$ be covex.</p>
<h2 id="Condtions-for-convexity-on-differentiable-functions">Condtions for convexity on differentiable functions<a class="anchor-link" href="#Condtions-for-convexity-on-differentiable-functions"> </a></h2><p><strong>First-order differentiability (informal):</strong> A function $f$ is differentiable if its domain is open and the gradient</p>
$$\nabla f(x) = \left(\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, ..., \frac{\partial f}{\partial x_n} \right)$$<p>exists at each $x \in \textbf{dom}~f$. From this follows a first-order condition for covexity.</p>
<p><strong>First-order condition:</strong> A differentiable function $f$ with a convex domain is convex if and only if</p>
$$f(x) \geq f(x_0) + \nabla f(x_0)^\top (x - x_0), \text{ for all } x_0, x \in \textbf{dom}~f.$$<p><strong>Second-order differentiability (informal):</strong> A function $f$ is twice differentiable if its domain is open and the hessian $\nabla^2 f(x) \in \mathbf{S}^n$ $$\nabla^2 f(x)_{ij} = \frac{\partial^2f(x)}{\partial x_i \partial x_j},~i, j = 1, ..., n,$$ exists at each $x \in \textbf{dom}~f$. From this follows a second-order condition for convexity.</p>
<p><strong>Second-order condition:</strong> A twice differentiable function $f$ with convex domain is</p>
\begin{align}
\text{convex if and only if }\nabla^2 f &amp;\succcurlyeq 0 \text{ for all } x \in \textbf{dom} f\\
\text{strictly convex if }\nabla^2 f &amp;\succ 0 \text{ for all } x \in \textbf{dom} f.
\end{align}<p>Note $f$ can be stricly convex and still have $\nabla^2 f = 0$ for some $x$ - take for example $f(x) = x^4$.</p>
<h2 id="More-examples-of-convex-functions">More examples of convex functions<a class="anchor-link" href="#More-examples-of-convex-functions"> </a></h2><p><strong>Quadratic function:</strong> $f(x) = \frac{1}{2} x^\top P x + q^\top x + r$ for $P \succ 0$.</p>
<p><strong>Least squares objective:</strong> $f(x) = ||Ax - b||_2^2$ for any $A, b$.</p>
<p><strong>Quadratic-over-linear:</strong> $f(x, y) = \frac{x^2}{y}$ for $y &gt; 0$.</p>
<p><strong>log-sum-exp or soft-max:</strong> $f(x) = \log \sum_{n = 1}^N e^{x_k}$.</p>
<p><strong>Geometric mean:</strong> $f(x) = \left(\prod_{i = 1}^n x_i\right)^{1/n}$ $x &gt; 0$.</p>
<h2 id="Epigraphs-and-sublevel-sets">Epigraphs and sublevel sets<a class="anchor-link" href="#Epigraphs-and-sublevel-sets"> </a></h2><p><strong>Sublevel set:</strong> The $\boldsymbol{\alpha}$-sublevel set of $f$ is</p>
$$C_\alpha = \{x \in \textbf{dom}~f~|~f(x) \leq \alpha \},$$<p>the set of $x$ for which $f(x)$ is no larger than $\alpha$. Sublevel sets of convex functions are convex.</p>
<p><strong>Epigraph:</strong> The epigraph of $f : \mathbb{R}^n \to \mathbb{R}$ is</p>
$$\textbf{epi}~f = \{(x, t) \in \mathbb{R}^{n + 1} | x \in \textbf{dom}~f, f(x \leq t)\},$$<p>the set of points which are on or above $f$ in $\mathbb{R}^{n + 1}$.</p>
<h2 id="Jensen's-inequality">Jensen's inequality<a class="anchor-link" href="#Jensen's-inequality"> </a></h2><p><strong>Convex function:</strong> The definition of a convex function</p>
$$f\big(\theta x + (1 - \theta)y\big) \leq \theta f(x) + (1 - \theta)f(y),$$<p>is a special case of Jensen's inequality.</p>
<p><strong>Jensen's inequality:</strong> If $f$ is convex and $\mathbb{E}$ is the expectation over a random variable $x$</p>
$$f\big(\mathbb{E}[x]\big) \leq \mathbb{E}\big[f(x)\big].$$<h2 id="Establishing-convexity">Establishing convexity<a class="anchor-link" href="#Establishing-convexity"> </a></h2><ol>
<li>Directly verify definition, for example by restricting to an arbitrary line and showing the restricted function is convex.</li>
<li>Show Hessian is positive semi-definite.</li>
<li>Show function can be obtained through a number of operations which preserve convexity.</li>
</ol>
<h3 id="Operations-that-preserve-convexity-of-sets">Operations that preserve convexity of sets<a class="anchor-link" href="#Operations-that-preserve-convexity-of-sets"> </a></h3><ul>
<li><strong>Nonnegative multiple:</strong> $\alpha f$ is convex if $f$ is convex and $\alpha \geq 0$.</li>
<li><strong>Sum:</strong> If $f_1$ and $f_2$ are convex, $f_1 + f_2$ is also convex. This extends to infinite sums and integrals.</li>
<li><strong>Composition with affine function:</strong> $f(Ax + b)$ is convex if $f$ is convex.</li>
<li><strong>Pointwise maximum:</strong> If $f_1, f_2, ..., f_n$ are all convex, then $$f(x) = \max \{f_1(x), f_2(x), ..., f_n(x)\},$$ is convex.</li>
<li><strong>Pointwise supremum:</strong> If $f(x, y)$ is convex in $x$ for each $y \in \mathcal{Y}$, then $$\DeclareMathOperator*{\sup}{sup} g(x) = \sup_{y \in \mathcal{Y}}f(x, y)$$ is also convex.</li>
<li><strong>Composition with scalar function:</strong> Given functions $g : \mathbb{R}^n \to \mathbb{R}$ and $h : \mathbb{R} \to \mathbb{R}$ their composition $$f(x) = h(g(x)),$$ is convex if (1) $g$ is convex, $h$ is convex and $\tilde{h}$ is nondecreasing; if (2) $g$ is concave, $h$ is convex and $\tilde{h}$ is nonincreasing.</li>
<li><strong>Vector composition:</strong> Composition with scalar functions can be extended to composition of vector functions. Suppose Given functions $g : \mathbb{R}^n \to \mathbb{R}^k$ and $h : \mathbb{R}^k \to \mathbb{R}$, then$$f(x) = h\big(g(x)\big) = h\big(g_1(x), g_2(x), ..., g_k(x)\big),$$ is convex if (1) $g_i$ are all convex, $h$ is convex and $\tilde{h}$ non-decreasing in each argument; (2) $g_i$ are all concave, $h$ is convex and $\tilde{h}$ non-increasing in each argument.</li>
</ul>

</div>
</div>
</div>
</div>

 


    </main>
    