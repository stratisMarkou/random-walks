---
interact_link: content/gaussian-processes/gp-intro.ipynb
kernel_name: venv-random-walks
kernel_path: content/gaussian-processes
has_widgets: false
title: |-
  Gaussian Processes
pagenum: 1
prev_page:
  url: /home.html
next_page:
  url: /gaussian-processes/sparse/intro.html
suffix: .ipynb
search: gp gps gaussian datasets approximation processes model regression classification scaling larger theoretical guarantees generalisation performance training conditionals process powerful nonparametric used tasks perform exctremely well small theoretically attractive properties interpretable challenges interesting leads study research cost making prediction optimising hyperparameters both scale mathcal o n large literature baking physical constraints into priors sometimes might strong prior function trying form constraint examples include modelling electromagnetic fields flow fluids obey maxwell navier stokes respectively test data new section fully independent fitc coming soon intro deterministic dtc variational free energy vfe

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Gaussian Processes</div>
</div>
    
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The Gaussian Process (GP) is a powerful nonparametric model, which can be used for tasks like regression or classification. GPs perform exctremely well in small datasets, have theoretically attractive properties and are interpretable.</p>
<h2 id="Challenges-and-interesting-leads-for-study-and-research">Challenges and interesting leads for study and research<a class="anchor-link" href="#Challenges-and-interesting-leads-for-study-and-research"> </a></h2><ul>
<li><strong>Scaling GPs to larger datasets:</strong> the cost of making a prediction or optimising the hyperparameters of a GP, both scale like $\mathcal{O}(N^3)$. There is a large literature on scaling GPs to larger datasets.</li>
<li><strong>Baking physical constraints into GP priors:</strong> sometimes, we might have a strong prior on the function we are trying to model, in the form of some constraint. Examples include modelling electromagnetic fields, or the flow of fluids, which would have to obey Maxwell and Navier-Stokes respectively.</li>
<li><strong>Theoretical guarantees about generalisation performance:</strong> What theoretical guarantees can one have about the generalisation performance of a GP to test data?</li>
</ul>
<h2 id="New-on-the-Gaussian-Processes-section">New on the Gaussian Processes section<a class="anchor-link" href="#New-on-the-Gaussian-Processes-section"> </a></h2><ul>
<li>Fully Independent Training Conditionals (FITC) approximation.</li>
</ul>
<h2 id="Coming-soon">Coming soon<a class="anchor-link" href="#Coming-soon"> </a></h2><ul>
<li>An intro to GPs for regression and classification</li>
<li>Deterministic Training Conditionals (DTC) approximation.</li>
<li>Variational Free Energy (VFE) approximation.</li>
</ul>

</div>
</div>
</div>
</div>

 


    </main>
    