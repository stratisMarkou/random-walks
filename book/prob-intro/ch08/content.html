
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Main limit theorems &#8212; Random Walks</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom_style.css?v=03c54da9" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-HP14V4DGEF"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-HP14V4DGEF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-HP14V4DGEF');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'book/prob-intro/ch08/content';</script>
    <link rel="icon" href="../../../_static/dicefav.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Masure, integration and real analysis" href="../../mira/000-intro.html" />
    <link rel="prev" title="Moment generating functions" href="../ch07/content.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Random Walks</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Home
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Notes on books and courses</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../toc/000-intro.html">Theory of Computation</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../toc/001-fsa.html">FSAs and Regular Expressions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../toc/002-cfl.html">PDAs and Context Free Grammars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../toc/000-exercises.html">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../intro.html">Probability: An introduction</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../ch01/content.html">Events and Probabilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ch02/content.html">Discrete random variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ch03/content.html">Multivariate discrete distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ch04/content.html">Probability generating functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ch05/content.html">Distribution and density functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ch06/content.html">Multivariate distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ch07/content.html">Moment generating functions</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Main limit theorems</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mira/000-intro.html">Measure Theory</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mira/001-riemann.html">Riemann integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mira/002-measures.html">Measures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mira/000-exercises.html">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../topology/000-intro.html">Topology</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../topology/001-metric-spaces.html">Metric spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../topology/002-topological-spaces.html">Topological Spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../topology/003-connectivity.html">Connectivity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../topology/004-compactness.html">Compactness</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../topology/exercises.html">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../lst/000-intro.html">Logic and set theory</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../lst/001-propositional-calculus.html">Propositional calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../lst/002-well-orderings-and-ordinals.html">Well-orderings and ordinals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../lst/exercises.html">Exercises</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Papers &amp; Miscellanous</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../papers/intro.html">Stream of papers</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../papers/swin/swin.html">Shifted window transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../papers/transformers/transformers.html">Introduction to transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../papers/why-covariances/why-covariances.html">Why covariance functions?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../papers/ais/ais.html">Annealed importance sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../papers/rff/rff.html">Random Fourier features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../papers/score-matching/score-matching.html">Estimation by score matching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../papers/svgd/svgd.html">Stein variational gradient descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../papers/num-sde/num-sde.html">Numerical simulation of SDEs</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/stratisMarkou/random-walks" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/stratisMarkou/random-walks/issues/new?title=Issue%20on%20page%20%2Fbook/prob-intro/ch08/content.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/book/prob-intro/ch08/content.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Main limit theorems</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-in-mean-square">Convergence in mean-square</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-in-probability">Convergence in probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#central-limit-theorem">Central limit theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-deviations">Large deviations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-in-distribution">Convergence in distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limits-of-characteristic-functions">Limits of characteristic functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="main-limit-theorems">
<h1>Main limit theorems<a class="headerlink" href="#main-limit-theorems" title="Link to this heading">#</a></h1>
<p>In this chapter we introduce the idea of convergence for random variables, which may be in either of the three senses: (1) in mean-square, (2) in probability or (3) in distribution.
These three senses are non-equivalent and in fact one implies the next, in the order given above.
We present important theorems involving limits of random variables, such as the law of large numbers, the central limit theorem and the large deviation theorem.
We also present the continuity theorems for moment generating functions and characteristic functions.</p>
<section id="convergence-in-mean-square">
<h2>Convergence in mean-square<a class="headerlink" href="#convergence-in-mean-square" title="Link to this heading">#</a></h2>
<p>We are often interested in the convergence of a sequence of random variables to another random variable.
Unlike real sequences, where convergence has one meaning only, the convergence of a sequence of random variables can be defined in different ways.
One such way is convergence in mean-square, as defined below.</p>
<div class="proof definition admonition" id="definition-0">
<p class="admonition-title"><span class="caption-number">Definition 46 </span> (Mean-square convergence)</p>
<section class="definition-content" id="proof-content">
<p>We say that a sequence of random variables <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> converges in mean square to a limit variable <span class="math notranslate nohighlight">\(X\)</span> if</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{E}\left[(X_n - X)^2\right] \to 0 \text{ as } n \to \infty,
\end{align}\]</div>
<p>and write this as <span class="math notranslate nohighlight">\(X_n \to X\)</span> in mean square as <span class="math notranslate nohighlight">\(n \to \infty\)</span>.</p>
</section>
</div><p>Note that for mean-square convergence to be meaningful, <span class="math notranslate nohighlight">\(\mathbb{E}(X)\)</span> as well as all <span class="math notranslate nohighlight">\(\mathbb{E}\left[(X_n - X)^2\right]\)</span> must exist.
We can use this definition to state one version of the mean square law of large numbers as follows.</p>
<div class="proof theorem admonition" id="theorem-1">
<p class="admonition-title"><span class="caption-number">Theorem 44 </span> (Mean square law of large numbers)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> be a sequence of independent random variables each with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2.\)</span>
Then</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\frac{1}{N}\sum_{n = 1}^N X_n \to \mu \text{ as } n \to \infty \text{ in mean square}.
\end{align}\]</div>
</section>
</div><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Proof: Mean-square law of large numbers<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">The partial sum <span class="math notranslate nohighlight">\(S_N = X_1 + X_2 + ... + X_N\)</span> has mean</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{E}\left(\frac{1}{N}S_N\right) &amp;= \frac{1}{N}\left[\sum_{n = 1}^N X_n\right] = \mu
\end{align}\]</div>
<p class="sd-card-text">and variance</p>
<div class="math notranslate nohighlight">
\[\begin{equation}
\text{Var}\left(\frac{1}{N} S_N\right) = \frac{1}{N^2}\text{Var}\left(S_N\right) = \frac{1}{N} \sigma^2.
\end{equation}\]</div>
<p class="sd-card-text">Where we used the facts that <span class="math notranslate nohighlight">\(\text{Var}(aX) = a^2\text{Var}(X),\)</span> and
that <span class="math notranslate nohighlight">\(\text{Var}(Y_1 + Y_2) = \text{Var}(Y_1) + \text{Var}(Y_2)\)</span> for any independent variables <span class="math notranslate nohighlight">\(Y_1\)</span> and <span class="math notranslate nohighlight">\(Y_2\)</span>.
Therefore as <span class="math notranslate nohighlight">\(N \to \infty\)</span>, <span class="math notranslate nohighlight">\(S_N \to \mu\)</span> in mean square.</p>
</div>
</details></section>
<section id="convergence-in-probability">
<h2>Convergence in probability<a class="headerlink" href="#convergence-in-probability" title="Link to this heading">#</a></h2>
<p>A weaker sense in which a sequence of random variables can converge is that of convergence in probability.</p>
<div class="proof definition admonition" id="definition-2">
<p class="admonition-title"><span class="caption-number">Definition 47 </span> (Convergence in probability)</p>
<section class="definition-content" id="proof-content">
<p>We say that a sequence of random variables <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> converges in probability to <span class="math notranslate nohighlight">\(X\)</span> as <span class="math notranslate nohighlight">\(n \to \infty\)</span> if for all <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}\left(|X_n - X| &gt; \epsilon\right) \to 0, \text{ as } n \to \infty,
\end{align}\]</div>
<p>and write this as <span class="math notranslate nohighlight">\(X_n \to X\)</span> in probability as <span class="math notranslate nohighlight">\(n \to \infty.\)</span></p>
</section>
</div><p>Convergence in probability is a weaker condition than convergence in mean-square in the sense that the former implies the latter, as stated by the following theorem.</p>
<div class="proof theorem admonition" id="theorem-3">
<p class="admonition-title"><span class="caption-number">Theorem 45 </span> (Convergence in mean square <span class="math notranslate nohighlight">\(\implies\)</span> convergence in probability)</p>
<section class="theorem-content" id="proof-content">
<p>If <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> is a sequence of random variables and <span class="math notranslate nohighlight">\(X_n \to X\)</span> in mean square, then <span class="math notranslate nohighlight">\(X_n \to X\)</span> in probability.</p>
</section>
</div><p>To prove the above we use Chebyshev’s inequality, a useful tool in probability theory, which is presented and proved below.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Proof: Convergence in mean square <span class="math notranslate nohighlight">\(\implies\)</span> convergence in probability<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">To show this result, we use Chebyshev’s inequality</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(|Z| \geq t) \leq \frac{\mathbb{E}\left(Z^2\right)}{t^2},
\end{align}\]</div>
<p class="sd-card-text">which proved below. Now set <span class="math notranslate nohighlight">\(Z = X_n - X\)</span> and <span class="math notranslate nohighlight">\(t = \epsilon &gt; 0\)</span> and let <span class="math notranslate nohighlight">\(n \to \infty\)</span> to obtain</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(|X_n - X| \geq \epsilon) \leq \frac{\mathbb{E}\left((X_n - X)^2\right)}{\epsilon^2} \to 0 \text{ as } n \to \infty,
\end{align}\]</div>
<p class="sd-card-text">where we have used the assumption that <span class="math notranslate nohighlight">\(X_n \to X\)</span> in mean square, so <span class="math notranslate nohighlight">\(\mathbb{P}\left(|X_n - X| \geq \epsilon\right) \to 0\)</span> as <span class="math notranslate nohighlight">\(n \to \infty.\)</span></p>
</div>
</details><div class="proof theorem admonition" id="theorem-4">
<p class="admonition-title"><span class="caption-number">Theorem 46 </span> (Chebyshev’s inequality)</p>
<section class="theorem-content" id="proof-content">
<p>If <span class="math notranslate nohighlight">\(X\)</span> is a random variable and <span class="math notranslate nohighlight">\(\mathbb{E}\left(X^2\right)\)</span> is finite then</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(|X| \geq t) \leq \frac{\mathbb{E}\left(X^2\right)}{t^2}.
\end{align}\]</div>
</section>
</div><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Proof: Chebyshev’s inequality<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Considering that <span class="math notranslate nohighlight">\(|X| \geq t \iff X^2 \geq t^2\)</span> we have</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(|X| \geq t) = \mathbb{P}(X^2 \geq t^2) \leq \frac{\mathbb{E}\left(X^2\right)}{t^2}.
\end{align}\]</div>
<p class="sd-card-text">by the <a class="reference internal" href="../ch07/content.html#prob-intro-markov-jensen"><span class="std std-ref">Markov inequality</span></a>, arriving at Chebyshev’s inequality.</p>
</div>
</details><p>Just as the law of large numbers can be stated in the mean-square sense, it can also be stated in the weaker sense of convergence in probability.</p>
<div class="proof theorem admonition" id="theorem-5">
<p class="admonition-title"><span class="caption-number">Theorem 47 </span> (Weak law of large numbers)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> be a sequence of independent random variables each with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2.\)</span> Then</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\frac{1}{N}\sum_{n = 1}^N X_n \to \mu \text{ as } n \to \infty \text{ in probability.}
\end{align}\]</div>
</section>
</div><p>This weak version is a direct implication of the fact that convergence in mean-square implies convergence in probability, as shown in the following proof.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Proof: Weak law of large numbers<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">We have shown that as (N \to \infty), the partial sum</p>
<div class="math notranslate nohighlight">
\[\begin{align}
S_N = X_1 + X_2 + ... + X_N
\end{align}\]</div>
<p class="sd-card-text">converges to <span class="math notranslate nohighlight">\(\mu\)</span> in mean square. Convergence in mean square implies convergence in probability, therefore <span class="math notranslate nohighlight">\(S_N\)</span> converges to <span class="math notranslate nohighlight">\(\mu\)</span> in probability too.</p>
</div>
</details><p>Unlike the mean-square law of large numbers, the weak law holds even when <span class="math notranslate nohighlight">\(\sigma^2\)</span> is infinite, provided that the <span class="math notranslate nohighlight">\(X_n\)</span> all come from the same distribution.</p>
</section>
<section id="central-limit-theorem">
<h2>Central limit theorem<a class="headerlink" href="#central-limit-theorem" title="Link to this heading">#</a></h2>
<div class="proof theorem admonition" id="theorem-6">
<p class="admonition-title"><span class="caption-number">Theorem 48 </span> (Central limit theorem)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1, X_2, \dots\)</span> be a sequence of independent and identically distributed random variables, each with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2.\)</span>
Then the random variable</p>
<div class="math notranslate nohighlight">
\[\begin{align}
Z_N = \frac{S_N - N\mu}{\sqrt{N}\sigma}, \text{ where } S_N = X_1 + X_2 + ... + X_N
\end{align}\]</div>
<p>satisfies, as <span class="math notranslate nohighlight">\(N \to \infty\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(Z_N \leq z) \to \int^z_{-\infty} \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}u^2} du, \text{ for } x \in \mathbb{R}.
\end{align}\]</div>
</section>
</div><div class="proof theorem admonition" id="theorem-7">
<p class="admonition-title"><span class="caption-number">Theorem 49 </span> (Continuity theorem with mgfs)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> be a sequence of random variables with moment generating functions <span class="math notranslate nohighlight">\(M_1, M_2 ...\)</span> and suppose that as <span class="math notranslate nohighlight">\(n \to \infty\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{align}
M_n(t) \to e^{\frac{1}{2}t^2} \text{ for } t \in \mathbb{R}
\end{align}\]</div>
<p>Then</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(Z_n \leq z) \to \int^z_{-\infty} \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}u^2} du, \text{ for } x \in \mathbb{R}.
\end{align}\]</div>
</section>
</div><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Proof: Central limit theorem<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(U_n = X_n - \mu\)</span>, so that the <span class="math notranslate nohighlight">\(U_n\)</span> are independent and identically distributed with mean <span class="math notranslate nohighlight">\(0\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. We will show that the mgf of</p>
<div class="math notranslate nohighlight">
\[\begin{align}
Z_N = \frac{S_N - N\mu}{\sigma\sqrt{N}}, \text{ where } S_N = X_1 + X_2 + ... + X_N
\end{align}\]</div>
<p class="sd-card-text">converges to the mgf of the standard normal.
Then, by applying the continuity theorem for mgfs, the distribution function of <span class="math notranslate nohighlight">\(Z_N\)</span> converges to the standard normal distribution.
Writing out the mgf of <span class="math notranslate nohighlight">\(Z_N\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
M_{Z_N}(t) &amp;= \mathbb{E}\left(\exp(tZ_N)\right)\\
&amp;= \mathbb{E}\left[\exp\left(\frac{t}{\sqrt{N}\sigma} \sum^N_{n=1} U_n \right)\right]\\
&amp;= \left[ M_U\left(\frac{t}{\sigma\sqrt{N}}\right) \right]^N
\end{align}\end{split}\]</div>
<p class="sd-card-text">where we have used the fact that the mgf of a sum of independent random variables (<span class="math notranslate nohighlight">\(U_n\)</span> in this case) is equal to the product of the mgfs of the random variables.
Now, taking the Taylor expansion of <span class="math notranslate nohighlight">\(M_{U_n}(t)\)</span> about <span class="math notranslate nohighlight">\(0\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
M_{U_n}(t) &amp;= 1 + t\mathbb{E}(U_n) + \frac{1}{2}t^2\mathbb{E}(U_n^2) + o(t^2)\\
&amp;= 1 + \frac{1}{2} \sigma^2 t^2 + o(t^2)
\end{align}\end{split}\]</div>
<p class="sd-card-text">so that</p>
<div class="math notranslate nohighlight">
\[\begin{align}
M_{Z_N}(t) = \left[ 1 + \frac{1}{2} \frac{t^2}{N} + o\left(\frac{1}{N}\right) \right]^N \to e^{\frac{1}{2}t^2} \text{ as } N \to \infty.
\end{align}\]</div>
<p class="sd-card-text">Therefore <span class="math notranslate nohighlight">\(M_{Z_N}(t) \to e^{\frac{1}{2}t^2}\)</span> as <span class="math notranslate nohighlight">\(N \to \infty\)</span> and by the continuity theorem for mgfs, the distribution function of <span class="math notranslate nohighlight">\(Z_N\)</span> converges to the standard normal distribution:</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(Z_N \leq z) \to \int^z_{-\infty} \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}u^2} du, \text{ for } x \in \mathbb{R}.
\end{align}\]</div>
</div>
</details></section>
<section id="large-deviations">
<h2>Large deviations<a class="headerlink" href="#large-deviations" title="Link to this heading">#</a></h2>
<p>We are sometimes interested in the probability that a sum of i.i.d. random variables <span class="math notranslate nohighlight">\(S_N = X_1 + X_2 + ... + X_N\)</span> will deviate from its mean by an amount proportional to <span class="math notranslate nohighlight">\(N\)</span>, i.e. <span class="math notranslate nohighlight">\(\mathbb{P}(S_N - \mu N &gt; aN).\)</span>
The large deviation theorem relates the probability of a large deviation to a quantity called the Fenchel-Legendre transform, defined below.</p>
<div class="proof definition admonition" id="definition-8">
<p class="admonition-title"><span class="caption-number">Definition 48 </span> (Fenchel-Legendre transform)</p>
<section class="definition-content" id="proof-content">
<p>Given a random variable <span class="math notranslate nohighlight">\(X\)</span>, with moment generating function <span class="math notranslate nohighlight">\(M\)</span>, its Fenchel-Legendre transform is</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\Lambda^*(a) = \sup\left\{at - \Lambda(t) : t \in \mathbb{R}\right\}, \text{ where } a \in \mathbb{R},
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Lambda(t) = \log M(t).\)</span></p>
</section>
</div><p>The large deviation theorem then takes the following form.</p>
<div class="proof theorem admonition" id="theorem-9">
<p class="admonition-title"><span class="caption-number">Theorem 50 </span> (Large deviation theorem)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> be independent, identically distributed random variables with mean <span class="math notranslate nohighlight">\(0\)</span> and a common generating function <span class="math notranslate nohighlight">\(M(t) = \mathbb{E}(e^{tX})\)</span> which is finite in some neighbourhood <span class="math notranslate nohighlight">\([-\delta, \delta]\)</span> of the origin.
Let <span class="math notranslate nohighlight">\(a &gt; 0\)</span> be such that <span class="math notranslate nohighlight">\(\mathbb{P}(X &gt; a) &gt; 0\)</span>. Then <span class="math notranslate nohighlight">\(\Lambda^*(a) &gt; 0\)</span> and</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\frac{1}{N} \log \mathbb{P}(S_N &gt; aN) \to - \Lambda^*(a), \text{ as } N \to \infty.
\end{align}\]</div>
</section>
</div><p>The proof of this theorem can be found in <em>Probability and Random Processes</em><span id="id1">[<a class="reference internal" href="#id5" title="G.R. Grimmett and D.R. Stirzaker. Probability and random processes. Number 391. Oxford university press, 2001.">Grimmett and Stirzaker, 2001</a>]</span> (section 5.11), but is ommitted from the book and these notes. Instead we prove below that</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\frac{1}{N}\log\mathbb{P}(S_N &gt; aN) \leq -\Lambda^*(a).
\end{align}\]</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Proof: Partial proof of the large deviation theorem<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> be a sequence of independent and identically distributed random variables with zero mean and common moment generating function <span class="math notranslate nohighlight">\(M(t)\)</span>, and define <span class="math notranslate nohighlight">\(S_N = X_1 + ... + X_N.\)</span>
For any strictly increasing function <span class="math notranslate nohighlight">\(g: \mathbb{R} \to \mathbb{R}\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[\begin{align}
S_N &gt; aN \iff g(S_N) &gt; g(aN).
\end{align}\]</div>
<p class="sd-card-text">The exponential function <span class="math notranslate nohighlight">\(g(x) = e^x\)</span> is strictly increasing and in addition it is non-negative, so</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(S_N &gt; aN) = \mathbb{P}(g(tS_N) &gt; g(taN)) \leq \frac{M(t)^N}{e^{taN}}, \text{ for } t &gt; 0,
\end{align}\]</div>
<p class="sd-card-text">by the <a class="reference internal" href="../ch07/content.html#prob-intro-markov-jensen"><span class="std std-ref">Markov inequality</span></a>.
Minimising over <span class="math notranslate nohighlight">\(t\)</span> we obtain</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(S_N &gt; aN) \leq \inf \left\{ \frac{M(t)}{e^{ta}} : \text{ for } t &gt; 0 \right\}^N
\end{align}\]</div>
<p class="sd-card-text">Taking a logarithm of each side, we arrive at the result</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\frac{1}{N}\log \mathbb{P}(S_N &gt; aN) \leq - \sup \left\{ ta - \Lambda(t) : \text{ for } t &gt; 0 \right\} = - \Lambda^*(a).
\end{align}\]</div>
</div>
</details></section>
<section id="convergence-in-distribution">
<h2>Convergence in distribution<a class="headerlink" href="#convergence-in-distribution" title="Link to this heading">#</a></h2>
<div class="proof definition admonition" id="definition-10">
<p class="admonition-title"><span class="caption-number">Definition 49 </span> (Convergence in distribution)</p>
<section class="definition-content" id="proof-content">
<p>The sequence <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> is said to converge in distribution, or to converge weakly, to <span class="math notranslate nohighlight">\(X\)</span> as <span class="math notranslate nohighlight">\(n \to \infty\)</span> if</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(X_n \leq x) \to \mathbb{P}(X \leq x), \text{ for any } x \in C,
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(C\)</span> is the set of reals at which the distribution function of <span class="math notranslate nohighlight">\(X\)</span> is continuous.
If the above holds, we write <span class="math notranslate nohighlight">\(X_n \implies X.\)</span></p>
</section>
</div><p>Convergence in distribution is a weaker condition than convergence in probability.
If the condition <span class="math notranslate nohighlight">\(x \in \mathbb{R}\)</span> was used instead of <span class="math notranslate nohighlight">\(x \in C\)</span> above, there would exist examples of sequences of random variables that would converge in probability but not in distribution.
By requiring that the criterion for convergence holds only where <span class="math notranslate nohighlight">\(\mathbb{P}(X \leq x)\)</span> is continuous, we avoid these cases and make convergence in probability a special case of the weaker criterion of convergence in distribution, as stated by the following theorem.</p>
<div class="proof theorem admonition" id="theorem-11">
<p class="admonition-title"><span class="caption-number">Theorem 51 </span> (Convergence in probability (\implies) convergence in distribution)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> be a sequence of variables and <span class="math notranslate nohighlight">\(X_n \to X\)</span> in probability, then <span class="math notranslate nohighlight">\(X_n \implies X\)</span>.</p>
</section>
</div><p>Below are two proofs for this result.
The first is a textbook proof from the book,<span id="id2">[<a class="reference internal" href="../intro.html#id3" title="G. Grimmett, D.J.A. Welsh, and D. Welsh. Probability: An Introduction. Oxford University Press. Clarendon Press, 1986.">Grimmett <em>et al.</em>, 1986</a>]</span> based on inequalities.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Proof: (a) Convergence in probability <span class="math notranslate nohighlight">\(\implies\)</span> convergence in distribution<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> be a sequence of random variables which converges in probability to another random variable <span class="math notranslate nohighlight">\(X\)</span>.
Let <span class="math notranslate nohighlight">\(x\)</span> be any point where the distribution function of <span class="math notranslate nohighlight">\(X\)</span> is continuous.
Now consider</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\mathbb{P}(X_n \leq x) &amp;= \mathbb{P}(X_n \leq x, X \leq x + \epsilon) + \mathbb{P}(X_n \leq x, X &gt; x + \epsilon)\\
&amp;\leq \mathbb{P}(X \leq x + \epsilon) + \mathbb{P}(X - X_n &gt; \epsilon)\\
&amp;\leq \mathbb{P}(X \leq x + \epsilon) + \mathbb{P}(|X - X_n| &gt; \epsilon)
\end{align}\end{split}\]</div>
<p class="sd-card-text">Similarly we can switch the roles of <span class="math notranslate nohighlight">\(X_n\)</span> and <span class="math notranslate nohighlight">\(X\)</span> to obtain</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\mathbb{P}(X \leq x - \epsilon) &amp;= \mathbb{P}(X \leq x - \epsilon, X_n \leq x) + \mathbb{P}(X_n \leq x - \epsilon, X &gt; x)\\
&amp;\leq \mathbb{P}(X_n \leq x) + \mathbb{P}(X_n - X &gt; \epsilon)\\
&amp;\leq \mathbb{P}(X_n \leq x) + \mathbb{P}(|X_n - X| &gt; \epsilon).
\end{align}\end{split}\]</div>
<p class="sd-card-text">Combining these two inequalities we obtain</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(X \leq x - \epsilon) - \mathbb{P}(|X_n - X| &gt; \epsilon) \leq \mathbb{P}(X_n \leq x) \leq \mathbb{P}(X \leq x + \epsilon) + \mathbb{P}(|X - X_n| &gt; \epsilon),
\end{align}\]</div>
<p class="sd-card-text">and taking <span class="math notranslate nohighlight">\(\epsilon\)</span> to <span class="math notranslate nohighlight">\(0\)</span> we obtain</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\mathbb{P}(X \leq x) \leq \mathbb{P}(X_n \leq x) \leq \mathbb{P}(X \leq x) \iff \mathbb{P}(X_n \leq x) = \mathbb{P}(X \leq x),
\end{align}\]</div>
<p class="sd-card-text">where we have used the facts that <span class="math notranslate nohighlight">\(X_n \to X\)</span> in probability and that <span class="math notranslate nohighlight">\(\mathbb{P}(X \leq x)\)</span> is continuous at <span class="math notranslate nohighlight">\(x.\)</span></p>
</div>
</details><p>The second is an alternative proof which includes a diagram, that is hopefully more intuitive.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Proof (b) Convergence in probability <span class="math notranslate nohighlight">\(\implies\)</span> convergence in distribution<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">The set <span class="math notranslate nohighlight">\(Z_n \leq z\)</span> corresponds to the yellow, red, green and pink regions below, and the set <span class="math notranslate nohighlight">\(Z \leq z\)</span> corresponds to the blue, orange, green and pink regions. Therefore the difference <span class="math notranslate nohighlight">\(\mathbb{P}(Z_n \leq z) - \mathbb{P}(Z \leq z)\)</span> is equal to the sum of the probability measure on the blue and orange regions, minus that of the yellow and red regions. We wish to show this difference goes to <span class="math notranslate nohighlight">\(0\)</span> as <span class="math notranslate nohighlight">\(n \to \infty.\)</span></p>
<p class="sd-card-text">Since <span class="math notranslate nohighlight">\(|Z_n - Z| \geq \epsilon\)</span> corresponds to <span class="math notranslate nohighlight">\((\text{white + green + blue + yellow})\)</span> and <span class="math notranslate nohighlight">\(\mathbb{P}(|Z_n - Z| \geq \epsilon) \to 0\)</span> as <span class="math notranslate nohighlight">\(n \to \infty\)</span>, the yellow and blue areas have <span class="math notranslate nohighlight">\(0\)</span> probability in the <span class="math notranslate nohighlight">\(n \to \infty\)</span> limit.
Assuming <span class="math notranslate nohighlight">\(\mathbb{P}(Z \leq z)\)</span> is continuous in <span class="math notranslate nohighlight">\(z\)</span> at <span class="math notranslate nohighlight">\(z = z_0\)</span>, then the red and orange areas must also have <span class="math notranslate nohighlight">\(0\)</span> probability in the <span class="math notranslate nohighlight">\(n \to \infty\)</span> limit, otherwise the continuity condition would be contradicted.
Therefore</p>
<div class="math notranslate nohighlight">
\[\lim_{n \to \infty} \big | \mathbb{P}(Z_n \leq z) - \mathbb{P}(Z \leq z) \big |  = 0,\]</div>
<p class="sd-card-text">and the variables converge in distribution.</p>
<figure class="align-default" id="conv-in-prob-proof">
<a class="reference internal image-reference" href="../../../_images/conv-in-prob-proof.svg"><img alt="../../../_images/conv-in-prob-proof.svg" height="500px" src="../../../_images/conv-in-prob-proof.svg" width="500px" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Illustration for the argument that convergence in probability implies convergence in distribution.
The presence of a darker border indicates that the corresponding region contains the border itself.
The cyan region does not contain its border.
See text for explanation.</span><a class="headerlink" href="#conv-in-prob-proof" title="Link to this image">#</a></p>
</figcaption>
</figure>
</div>
</details><div class="proof theorem admonition" id="theorem-12">
<p class="admonition-title"><span class="caption-number">Theorem 52 </span> (Convergence in distribution to <span class="math notranslate nohighlight">\(c\)</span> <span class="math notranslate nohighlight">\(\implies\)</span> convergence in probability to <span class="math notranslate nohighlight">\(c\)</span>)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X_1, X_2, ...\)</span> be a sequence of variables and which coverges in distribution to a constant <span class="math notranslate nohighlight">\(c\)</span>.
Then <span class="math notranslate nohighlight">\(X_n\)</span> converges to <span class="math notranslate nohighlight">\(c\)</span> in probability also.</p>
</section>
</div></section>
<section id="limits-of-characteristic-functions">
<span id="prob-intro-char-cont"></span><h2>Limits of characteristic functions<a class="headerlink" href="#limits-of-characteristic-functions" title="Link to this heading">#</a></h2>
<div class="proof theorem admonition" id="theorem-13">
<p class="admonition-title"><span class="caption-number">Theorem 53 </span> (Continuity theorem with characteristic functions)</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(X, X_1, X_2, ...\)</span> be random variables with characteristic functions <span class="math notranslate nohighlight">\(\phi, \phi_1, \phi_2 \dots .\)</span>
Then <span class="math notranslate nohighlight">\(X_N \implies X\)</span> as <span class="math notranslate nohighlight">\(N \to \infty\)</span> if and only if</p>
<div class="math notranslate nohighlight">
\[\begin{align}
\phi_N(t) \to \phi(t) \text{ as } N \to \infty, \text{ for } t \in \mathbb{R}.
\end{align}\]</div>
</section>
</div></section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id3">
<div role="list" class="citation-list">
<div class="citation" id="id4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">GWW86</a><span class="fn-bracket">]</span></span>
<p>G. Grimmett, D.J.A. Welsh, and D. Welsh. <em>Probability: An Introduction</em>. Oxford University Press. Clarendon Press, 1986.</p>
</div>
<div class="citation" id="id5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">GS01</a><span class="fn-bracket">]</span></span>
<p>G.R. Grimmett and D.R. Stirzaker. <em>Probability and random processes</em>. Number 391. Oxford university press, 2001.</p>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book/prob-intro/ch08"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../ch07/content.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Moment generating functions</p>
      </div>
    </a>
    <a class="right-next"
       href="../../mira/000-intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Masure, integration and real analysis</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-in-mean-square">Convergence in mean-square</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-in-probability">Convergence in probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#central-limit-theorem">Central limit theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-deviations">Large deviations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-in-distribution">Convergence in distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limits-of-characteristic-functions">Limits of characteristic functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Stratis Markou
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>